# 计算机科学速成课 

- **从高层次总览一系列计算机话题，快速入门计算机科学**



- ### 精校版    


https://www.bilibili.com/video/av21376839/     

<br/>

![bilibili](/image/cs40.jpg)    

- ### 原视频


[Youtube - Crash Course Computer Science Playlist](https://www.youtube.com/playlist?list=PL8dPuuaLjXtNlUrzyH5r6jN9ulIgZBpdo)     
![Crash Course CS screenshoht](/image/english.png)



- ### 大致目录

* 1 - [早期的计算 - Early Computing](https://www.bilibili.com/video/av8861057/)
* 2 - [电子计算 - Electronic Computing](https://www.bilibili.com/video/av9066628/)
* 3 - [布尔逻辑与逻辑电路 - Boolean Logic & Logic Gates](https://www.bilibili.com/video/av11557339/)
* 4 - [二进制 - Representing Numbers and Letters with Binary](https://www.bilibili.com/video/av11592079/)
* 5 - [算术逻辑单元 - How Computers Calculate - the ALU](https://www.bilibili.com/video/av12742941/)
* 6 - [寄存器 & 内存 - Registers and RAM](https://www.bilibili.com/video/av12881796/)
* 7 - [中央处理器 - The Central Processing Unit(CPU)](https://www.bilibili.com/video/av12881976/)
* 8 - [指令和程序 - Instructions & Programs](https://www.bilibili.com/video/av9875360/)
* 9 -  [高级 CPU 设计 - Advanced CPU Designs](https://www.bilibili.com/video/av11867964/)
* 10 - [编程史话 - Early Programming](https://www.bilibili.com/video/av13582556/)
* 11 - [编程语言 - The First Programming Languages](https://www.bilibili.com/video/av14228148/)
* 12 - [编程原理：语句和函数 - Programming Basics: Statements & Functions](https://www.bilibili.com/video/av14885759/)
* 13 - [算法初步 - Intro to Algorithms](https://www.bilibili.com/video/av15987761/)
* 14 - [数据结构 - Data Structures](https://www.bilibili.com/video/av15987774/)
* 15 - [阿兰·图灵 - Alan Turing](https://www.bilibili.com/video/av16090115/)
* 16 - [软件工程 - Software Engineering](https://www.bilibili.com/video/av16751202/)
* 17 - [集成电路、摩尔定律 - Integrated Circuits & Moore’s Law](https://www.bilibili.com/video/av17186768)
* 18 - [操作系统 - Operating Systems](https://www.bilibili.com/video/av17192468)
* 19 - [内存 & 储存介质 - Memory & Storage](https://www.bilibili.com/video/av17192483/)
* 20 - [文件系统 - Files & File Systems](https://www.bilibili.com/video/av17209268/)
* 21 - [压缩 - Compression](https://www.bilibili.com/video/av17192511/)
* 22 - [命令行界面 - Keyboards & Command Line Interfaces](https://www.bilibili.com/video/av17451718/)
* 23 - [屏幕 & 2D 图形显示 - Screens & 2D Graphics](https://www.bilibili.com/video/av17476087/)
* 24 - [冷战和消费主义 - The Cold War and Consumerism](https://www.bilibili.com/video/av15637307/)
* 25 - [个人计算机革命 - The Personal Computer Revolution](https://www.bilibili.com/video/av18789303/)
* 26 - [图形用户界面 - Graphical User Interfaces](https://www.bilibili.com/video/av19035296/)
* 27 - [3D 图形 - 3D Graphics](https://www.bilibili.com/video/av19164942/)
* 28 - [计算机网络 - Computer Networks](https://www.bilibili.com/video/av19209394/)
* 29 - [互联网 - The Internet](https://www.bilibili.com/video/av20716104/)
* 30 - [万维网 - The World Wide Web](https://www.bilibili.com/video/av20767130/)
* 31 - [网络安全 - Cybersecurity](https://www.bilibili.com/video/av20785456/)
* 32 - [黑客与攻击 - Hackers & Cyber Attacks](https://www.bilibili.com/video/av20831479/)
* 33 - [加密 - Cryptography](https://www.bilibili.com/video/av20882310/)
* 34 - [机器学习与人工智能 - Machine Learning & Artificial Intelligence](https://www.bilibili.com/video/av20922906)
* 35 - [计算机视觉 - Computer Vision](https://www.bilibili.com/video/av20974735)
* 36 - [自然语言处理 - Natural Language Processing](https://www.bilibili.com/video/av21004070)
* 37 - [机器人 - Robots](https://www.bilibili.com/video/av21043523)
* 38 - [计算机中的心理学 - Psychology of Computing](https://www.bilibili.com/video/av21066931)
* 39 - [教育型科技 - Educational Technology](https://www.bilibili.com/video/av21103744)
* 40 - [(完结) 奇点，天网，计算机的未来 - The Singularity, Skynet, and the Future of Computing](https://www.bilibili.com/video/av21126704)      





## 第 1 集：计算机早期历史  
设备：算盘 → 步进计算器 → 差分机 → 分析机 → 打孔卡片制表机  
人名：Charles Babbage, Ada Lovelace  

1. 公元前 2500 年，算盘出现。算盘是十进制的手动计算器，用来帮助加减数字。
2. 公元前 2500 年-公元 1500 年，星盘、计算尺、时钟等依靠机械运动的计算设备出现。
3. 公元 1613 年，computer 的概念出现，当时指的是专门做计算的职业。1800 年代之后 "Computer" 逐渐开始代表机器。
4. 1694 年，步进计算器出现。这是世界上第一台能自动完成加减乘除的计算器，沿用了 3 个世纪。
5. 1694-1900 年，计算表兴起，类似于字典，可用于查找各种庞大的计算值。军队中，为了精确瞄准炮弹，出现了射程表，炮手可以查环境条件和射击距离。
6. 1823 年，差分机的设想出现，可以做函数计算，但计划最后失败。在 1991 年，历史学家根据 Charles Babbage 的草稿做了一个差分机。
7. 19 世纪中期，分析机的设想出现，设想存在可计算一切的通用计算机。英国数学家 Ada Lovelace 给分析机写了假想的程序，她表示"未来会诞生一门全新的，强大的，专为分析所用的语言"。因此 <u>*Ada 被认为是世上第一位程序员*</u>。
8. 1890 年，打孔卡片制表机出现。原理：在纸上打孔→孔穿过针→针泡入汞→电路连通→齿轮使计数+1。



## 第 2 集：电子计算机

**电子计算机元器件（开关）变化：继电器→真空管（vacuum tube）→晶体管（transistor）**



1.20 世纪人口暴增，科学与工程进步迅速，航天计划成形。以上导致数据的复杂度急剧上升、计算量暴增，对于计算的自动化、高速有迫切的需求。柜子大小的计算机发展到房间大小。  



2.1944 年,IBM完成了给二战同盟国的哈佛马克 1（Harvard Mark I）的建造，最早用于给"曼哈顿计划"跑模拟：

- 使用<u>**继电器**</u>，利用电磁效应控制机械开关，缺点是**有延迟、速度慢和磨损**。

- 因为有虫子飞进去导致故障，引申出 bug=故障的意思。

  

3.

1904 年，继电器的替代品热电子管（第一个真空管）就已经出现，改进后也能作为开关。

1940 年代，真空管的成本和可靠性得到改进，计算机 从机电转向电子。

- 真空管内没有会动的组件，这意味着更少的磨损；更重要的是，每秒可以开闭数千次，但也像灯泡一样会烧坏。

4.1943 年 ，第一个**<u>大规模使用真空管</u>**的计算机 "巨人1号"（Colossus MK 1）完成建造， 用于破解纳粹通信。这是世界上**第一个可编程**的计算机，但编程麻烦，还要配置。

5.1946 年，第一个电子通用数值积分计算机 "ENIAC"，在"宾夕法尼亚大学"完成建造。这是世上**第一个真正的通用，可编程的电子计算机**。

6.1950s ，空军 ANFSQ-7： 真空管到达计算极限。



7.1947 年，贝尔实验室科学家发明了晶体管（半导体），开关频率更快，固态不易碎，而且远远小于继电器或真空管，计算机变得更小更便宜。

- *硅谷的典故：很多晶体管和半导体的开发都是这里做的。而生产半导体最常见的材料是硅 。

- *肖克利半导体 → 仙童半导体 → 英特尔

8.IBM 很快把所有产品都转向了晶体管，把晶体管计算机带入办公室，最终引入家庭。1957 年 IBM 608： 第一个消费者可购买的晶体管计算机出现。




## 第 3 集：布尔逻辑和逻辑门  
计算机为什么使用二进制：

1. 计算机的元器件晶体管只有 2 种状态，**通电（1）&断电（0）**，用二进制可直接根据元器件的状态来设计计算机。

1. 数学中的“布尔代数”分支，可以用 True 和 False（可用 1 代表 True，0 代表 False）进行逻辑运算，代替实数进行计算。

1. 计算的状态越多，信号越容易混淆，影响计算。对于当时每秒运算百万次以上的晶体管，信号混淆是特别让人头疼的的。
2. 


## 第 4 集：二进制  


### 0、**计算机中表示数字的方法**

1 、整数：

表示方法:

- 第 1 位：表示正负， 1 是负，0 是正（补码）

- 其余 31 位/63 位： 表示实数

2 浮点数（Floating Point Numbers）：小数点可在数字间浮动的数（非整数）

表示方法：IEEE 754 标准下，用类似科学计数法的方式，存储十进制数值

- 浮点数=有效位数*指数

- 32 位数字中：第 1 位表示正负，第 2-9 位存指数。剩下 23 位存有效位数

eg.625.9=0.6259（有效位数）*10^3（指数）



### 1、美国信息交换标准代码-ASCⅡ

 作用：用数字给英文字母及符号编号

 内容：7 位代码，可存放 128 个不同的值。



### 2、统一码/万国码-UNICODE

作用：随着计算机在亚洲兴起，需要解决 ASCⅡ不够表达所有语言的问题。为提高代码的互用性，这套统一所有字符编码的标准**在1992 诞生。

内容：UNICODE 为 17 组的 16 位数字，有超过 100 万个位置，可满足所有语言的字符需求。 




## 第 5 集：算数逻辑单元 -**A**rithmetic&**L**ogic Unit， ALU  
### 0、**算术逻辑单元**

组成：ALU 有 2 个单元，**1 个算术单元和 1 个逻辑单元**（Arithmetic Unit 和 Logic Unit）

作用：计算机中负责运算的组件，**处理数字/逻辑运算的最基本单元**。



### 1、算术单元

1）基本组件：

- 由半加器、全加器组成

- 半加器、全加器由 AND、OR、NOT、XOR 门组成

2）加法运算

1.半加器：

- 作用：用于计算个位的数字加减。

- 输入：A，B ；输出：总和，进位

  <img src="E:\自我提升\计算机科学速成课\image\e5-half adder.png" style="zoom: 50%;" />


2 全加器：

- 作用：用于计算超过 1 位的加法（ex：1+1+1），由于涉及进位，因此有 3 个输入（C 充当进位）。

- 用半加器可以组成全加器

![](E:\自我提升\计算机科学速成课\image\e5-full adder-logical table.png)

3 用半加器与全加器做 8 位数的加法（8 位行波加法器）

![e5-8 bit adder](E:\自我提升\计算机科学速成课\image\e5-8 bit adder.png)

*可能存在溢出（overflow）

*上述这种串行式的加法计算花费时间很长，所以现在电脑使用的加法器叫“**超前进位加法器**”



3）算术单元支持的其他运算

![e5-ohter arithmetic compute](E:\自我提升\计算机科学速成课\image\e5-ohter arithmetic compute.png)

*简单处理器中，乘法一般是转换成加法计算；在笔记本和手机中有更好的处理器，有专门做乘法的算术单元，乘法电路比较复杂，需要更多逻辑门



### 2、逻辑单元

作用：执行逻辑操作，如 NOT、AND、OR 等操作，以及做简单的数值测试。



### 3、ALU 的抽象

1）作用：ALU 的抽象让工程师不再考虑逻辑门层面的组成，简化工作。

2）图示：像一个大**“V”**。

![e5-ALU symbal](E:\自我提升\计算机科学速成课\image\e5-ALU symbal.png)

3）说明（图示内容包括）：

- 输入 A，B
- 操作代码（决定进行什么运算）

- 输出

- 标志：溢出、零检测、负数

  ![e5-ALU detail](E:\自我提升\计算机科学速成课\image\e5-ALU detail.png)

## 第 6 集：寄存器和内存  



### 0、概念梳理

**随机存取存储器**（Random Access Memory,RAM）：俗称内存。将一堆独立的存储模块和电路看做 1 个单元，组成内存方块，n 个内存方块组成内存模块，在一个电路板上所有的内存方块统称为内存。内存的重要特性是可以**随时访问任何位置**，所以又叫随机存取存储器。内存只能在通电情况下存储数据，类似于人类的短时记忆。

**锁存器**（Gated Latch）：锁存器是利用 AND、OR、NOT 逻辑门，实现存储 1 位数字的器件。

**寄存器**（register）：1 组并排的锁存器，寄存器能存储的数字位数叫做位宽（width）

**矩阵**：以矩阵的方式来存放锁存器的组合件，门锁矩阵可存放 n^2 个锁存器，但同一时间只能写入/读取 1 个数字。（早期为 16*16 矩阵）

**位址**：锁存器在矩阵中的行数与列数。eg.12 行 8 列

**多路复用器**：一组电线，输入 2 进制的行址&列址，可启用矩阵中某个锁存器



### **1、锁存器**

作用：存储 1 位数字。

图示：

![e6-latch](E:\自我提升\计算机科学速成课\image\e6-latch.png)



### 2、门锁

锁存器需要同时输入 2 个数字，不太方便。

为了使用更方便，只用 1 根电线控制数据输入，用另一根电线来控制整个结构的开关，发展了门锁这个器件。

![e6-gate latch](E:\自我提升\计算机科学速成课\image\e6-gate latch.png)

*当允许写入线输入高电平时，数据输出随着数据输入的变化而变化；

*当允许写入线输入低电平时，数据输出随着数据输入的变化而变化；



### 3、寄存器

作用：并排使用门锁，存储多位数字

图示：

![e6-8 bit register](E:\自我提升\计算机科学速成课\image\e6-8 bit register.png)



### **4、门锁矩阵**

作用：

n*n 的矩阵有 n^2 个位址，则可以存储 n^2 个数。

但 1 个矩阵只可记录 1 位数字，n 个矩阵组合在一起，才可记录 n 位数。如 1 个 8 位数，会按位数分成 8 个数，分别存储在 8 个矩阵的同一个位址中。8 个矩阵，则可以记录 256 个 8 位数字。

图示：

![e6-latch matrix](E:\自我提升\计算机科学速成课\image\e6-latch matrix.png)



![e6-latch matrix principle](E:\自我提升\计算机科学速成课\image\e6-latch matrix principle.jpg)



### 5、**多路复用器** 

多路复用器(Multiplexer) 解码 8 位地址，定位到单个锁存器  

![e6-mutiplexer](E:\自我提升\计算机科学速成课\image\e6-mutiplexer.jpg)

256位内存抽象

![e6-256 bit memory abstraction](E:\自我提升\计算机科学速成课\image\e6-256 bit memory abstraction.png)

<img src="E:\自我提升\计算机科学速成课\image\e6-8 256 memory .png" style="zoom: 33%;" />

<img src="E:\自我提升\计算机科学速成课\image\e6-8 256 bit memory abstraction.png" alt="e6-8 256 bit memory abstraction" style="zoom:25%;" />



## 第 7 集：中央处理器（CPU)  



### 0、概念梳理

- **中央处理单元**（Central Processing Unit，CPU）：通常由寄存器/控制单元/ALU/时钟组成，与 RAM 配合，执行计算机程序。CPU 和 RAM 之间用“地址线”、“数据线”和“允许读/写线”进行通信。
- **指令**：指示计算机要做什么，多条指令共同组成程序。如数学指令，内存指令。
- **时钟**：负责管理 CPU 运行的节奏，以精确的间隔触发电信号，控制单元用这个信号，推动 CPU 的内部操作。
- **时钟速度**：CPU 执行“取指令→解码→执行”中每一步的速度叫做“时钟速度”，单位赫兹Hz，表示频率。
- **超频/降频**：很多现代处理器可以按需求加快或减慢时钟速度，这叫“动态调整频率”
  - 超频（overclocking），修改时钟速度，加快 CPU 的速度。芯片制造商经常给CPU留一点余地，可以接受一点超频，超频过多会让 CPU 过热或产生乱码（信号跟不上时钟）。
  - 降频（underclocking），降低时钟速度，达到**省电**的效果，对笔记本/手机很重要。
- **微体系框架**：以高层次视角看计算机，如当我们用一条线链接 2 个组件时，这条线只是所有必须线路的抽象。



### 1、CPU 工作原理

**1）必要组件：**

- 指令表：给 CPU 支持的所有指令分配 ID,即操作代码（operation code）,简称操作码（opcode）

- 控制单元：像指挥部，有序的控制指令的读取、运行与写入。

- 指令地址寄存器：追踪程序运行到哪里了，存当前指令的内存地址。该器件只按顺序通报地址，让 RAM 按顺序将指令交给指令寄存器。

- 指令寄存器：存储当前指令。


**2）过程**

- **取指令**（fetch)：指令地址寄存器发地址给 RAM→RAM发该地址内的数据给指令寄存器→指令寄存器接受数据
- **解码**(decode)：指令寄存器根据数据发送指令给控制单元 →控制单元解码（逻辑门确认操作码）
- **执行**(execute)：控制单元执行指令(→涉及计算时→调用所需寄存器→传输入&操作码给ALU执行）→调用RAM特定地址的数据→RAM将结果传入寄存器→指令地址寄存器+1
- CPU可以执行各种指令，不同的指令由不同逻辑电路编码，这些逻辑电路会配置CPU内的组件来执行对应操作

![](E:\自我提升\计算机科学速成课\image\e7-instruction table.png)

![e7-components](E:\自我提升\计算机科学速成课\image\e7-components.jpg)

![e8-simplified](E:\自我提升\计算机科学速成课\image\e8-simplified.png)

该CPU功能是从RAM取两个值相加再存回RAM。值得一提的是，该程序没有停止命令，STORE_A 13 之后，CPU会不停运行下去，处理后面的0,因为0不是操作码，所以电脑会崩掉。


## 第 8 集：指令和程序  
### 0、概念梳理

- 指令：指示计算机要做什么的代码（机器码），多条指令共同组成程序。如数学指令，内存指令。

  - 注:指令和数据都是存在同一个内存里的。

- 指令集：记录指令名称、用法、操作码以及所需 RAM 地址位数的表格。



### 1、指令的执行

- 原则：RAM 每一个地址中，都存放 0 或 1 个数据。特定的数字组合，就表示为一个指令，否则表示一个值。

- LOAD 指令：计算机会按地址的顺序，读取 RAM 中所记录的指令/数据。计算机接受到指令后，如 LOAD_A，则通过数据线将数据传至寄存器 A。
- STORE指令：STORE_A，将A寄存器上的数据存储到RAM的特定地址中

- ADD 指令：ADD B A 指令告诉 ALU，把寄存器 B 和寄存器中的数字加起来，存到寄存器 A 中。
- SUB指令

- JUMP 指令：遇到 JUMP 指令，程序会跳转至对应的 RAM 地址读取数据。JUMP 指令可以有条件跳转（如 JUMP-negative，JUMP_IF_EQUAL,JUMP_IF_GREATER），也可以无条件跳转。
- HALT指令：停止程序



### 2、计算机指令长度

由于早期计算机每个字只有 8 位，指令只占 4 位，意味着只能有 16 个指令，这远远不够。

现代计算机有两种方式解决指令不够用的问题：

1）最直接的是用**更多位来表示指令**，如 32 位或 64 位，这个位数也叫做**指令长度**

2）采用“**可变指令长度**”，令不同的指令的长度不同，尽量节约位数。

如果看到 HALT 指令，HALT 不需要额外数据,则可以省去寻址的位数。

如果看到 JUMP，它得知道位置值,这个值在 JUMP 的后面,这叫 "立即值"(Immediate Value)
这样设计，指令可以是任意长度,但会让读取阶段复杂一点点。



## 第 9 集：高级 CPU 设计  

02:28  给 CPU 加缓存，提高数据存取速度，更快喂给 CPU，用计算餐馆销售额举例  
05:13  脏位 -  Dirty bit  
05:33  流水线设计，用 1 个洗衣机和 1 个干燥机举例  
06:01  并行处理 -  parallelize  
07:33  乱序执行 -  out-of-order execution  
08:21  推测执行 -  speculative execution  
08:50  分支预测 -  branch prediction  
09:34  多个 ALU  
09:54  多核 (Core)  
10:11  多个独立 CPU  
10:52  超级计算机，中国的&quot;神威 太湖之光&quot;  

### 0、概念梳理

- 缓存（cache）：在 CPU 中的小块 RAM，用于存储批量指令。

- 缓存命中（cache hit）：想要的数据已经在缓存里

- 缓存未命中（cache miss）：想要的数据不在缓存里

- 脏位（dirty bit）：缓存里每块空间，有个特殊标记，叫脏位，用于检测缓存内的数据是否与 RAM 一致。

- 多核处理器：一个 CPU 芯片中，有多个独立处理单元。



### 1、现代 CPU 如何提升性能

早期通过**加快晶体管的切换速度**，来提升 CPU 速度。但很快该方法到达了极限。

后来给 CPU 设计了**专门除法电路+其他电路**来做复杂操作：如游戏，视频解码




### 2、缓存

**RAM 是 CPU 之外的独立组件**，意味着数据要用"总线"来传递。

因为**从 RAM 到 CPU 的数据传输有延迟**（要通过总线，RAM 还要时间找地址、取数据、配置、输出数据），CPU在空等数据。

为了不让 CPU 空等数据，在 CPU 内部设置了一小块内存，称为缓存，让 RAM 可以一次传输一批数据到 CPU 中。（不加缓存，CPU 没位置放大量数据。）

缓存也可以当临时空间，存一些中间值，适合长/复杂的运算。

因为处理器里空间不大，所以缓存一般只有 KB 或 MB，而 RAM 都是 GB 起步



缓存同步一般发生在 CPU 缓存已满，但 CPU 仍需往缓存内输入数据。在清理缓存腾出空间之前，会先检查 "脏位"。如果是"脏"的, 在加载新内容之前, 会把数据写回 RAM。被标记为脏位的数据会优先传输回 RAM,腾出位置以防被覆盖，导致计算结果有误。



### 3、指令流水线（instruction pipelining）

作用：让取址→解码→执行三个步骤同时进行,并行执行指令，提升CPU性能。

原本需要 3 个时钟周期执行 1 个指令，现在只需要 1 个时钟周期。



设计难点：

1）指令之间的依赖关系

流水线处理器数据依赖性解决方法：**乱序运行**（关断CPU：动态排序有依赖关系的指令，最小化流水线的停工时间）

2）条件跳转

这些指令会改变程序的执行流。简单的流水线处理器，看到 JUMP 指令会停一会儿等待条件值确定下来，一旦 JUMP 的结果出了，处理器就继续流水线。因为空等会造成延迟，所以高端处理器会用一些技巧。可以把 JUMP 想成是 "岔路口"，高端 CPU 会猜哪条路的可能性大一些然后提前把指令放进流水线，这叫 **"推测执行"**（speculative execution）。当 JUMP 的结果出了，如果 CPU 猜对了，流水线已经塞满正确指令，可以马上运行。如果 CPU 猜错了，就要清空流水线，就像走错路掉头。为了尽可能减少清空流水线的次数，CPU 厂商开发了复杂的方法，来猜测哪条分支更有可能，叫**"分支预测"**（branch prediction）。现代 CPU 的正确率超过 90%。



**"超标量处理器"**（superscalar processors）一个时钟周期完成多个指令







### 3、多核处理器**（multi-core processors）

**缓存和指令流水线都是优化1个指令流的吞吐量**，但多核CPU可以同时运行多个指令流。

**多核处理器**（multi-core processors）：一个 CPU 芯片中，有多个独立处理单元。但因为它们整合紧密，可以共享一些资源，比如缓存，使得多核可以合作运算。



### 4、超级计算机（多个 CPU）

多核不够时，可以用多个CPU。

截止至视频发布，世上最快的计算机在中国无锡的国家超算中心.神威·太湖之光有 40960 个CPU，每个 CPU 有 256 个核心。总共超过1千万个核心，每个核心的频率是 1.45GHz。每秒可以进行 9.3 亿亿次浮点数运算，也叫每秒浮点运算次数 (FLOPS：floating point math operations per second)。



## 第 10 集：早期的编程方式  


### 1、早期计算机的编程（如何将程序输入计算机）

- **打孔纸卡(Punched card )/纸带**：在纸卡上打孔，用读卡器读取连通电路，进行编程。
- 原因，穿孔纸卡便宜、可靠也易懂。62500 张纸卡=5MB 数据
- **插线板**(Plug board )：通过插拔线路的方式，改变器件之间的连接方式，进行编程。但这种方式非常麻烦
- **面板（panel）开关、（1980s 前）：随着内存价格下降, 容量上升。 与其把程序存在插线板,存在内存变得可行,这样程序易于修改、方便 CPU 快速读取,这类机器叫 "存储程序计算机"( Stored-program Computers)。人们可以通过面板编程。通过拨动面板上的开关，进行编程。输入二进制操作码，按存储按钮，推进至下一个内存位，直至操作完内存，按运行键执行程序。（内存式电脑）




### 2、现代计算机基础结构——冯诺依曼计算机

程序和数据都存在一个地方，叫 **"冯诺依曼结构"**(Von Neumann Architecture)

冯诺依曼计算机的标志是，**一个处理器(有算术逻辑单元)+数据寄存器+指令寄存器+指令地址寄存器+内存**

a processing unit containing an arithmetic logic unit,data registers, instruction register ,instruction address register and finally a memory to store both data and instructions


## 第 11 集：编程语言发展史  
编程：二进制 → 助记符（汇编器）→ A-0（编译器）→ FORTRAIN  



### 1、机器语言（二进制）

早期，人们先在纸上写**伪代码**（Pseudo-Code），用"操作码表"把伪代码转成二进制机器码，翻译完成后，程序可以喂入计算机并运行。



### 2、汇编器&助记符

1940~1950s，程序员开发出一种新语言， 更可读更高层次的（汇编码）。

每个操作码分配一个简单名字，叫"**助记符**"（mnemonics）。"助记符"后面紧跟数据，形成完整指令。但计算机不能读懂“助记符”，因此人们写了二进制程序“**汇编器**"（Assembler）来帮忙。汇编器读取用"汇编语言"写的程序，然后转成"机器码"。

随着时间推移，汇编器有越来越多功能，让编程更容易，其中一个功能是自动分析 JUMP 地址：JUMP指令跳到特定的地址，但如果在程序开头多加一些代码，所有地址都会变，更新程序会很痛苦！汇编器不用固定跳转地址，而是让你插入可跳转的标签，当程序被传入汇编器，汇编器会自己搞定跳转地址。程序员可以专心编程，不用管底层细节，隐藏不必要细节来做更复杂的工作。

### 3、最早高级编程语言“A-0”

汇编只是修饰了一下机器码，一般来说，一条汇编指令对应一条机器指令，所以汇编码和底层硬件的连接很紧密，汇编器仍然强迫程序员思考底层逻辑。



1950s，为释放超算潜力，葛丽丝·霍普博士，设计了一个高级编程语言，叫 "Arithmetic Language Version 0"，一行高级编程语言 可以转成几十条二进制指令。为了做到这种复杂转换，Hopper 在 1952 年创造了第一个编译器，专门把高级语言转成低级语言。但由于当时人们认为，计算机只能做计算，而不能做程序，A-0 未被广泛使用。



过程：**高级编程语言→编译器→汇编码/机器码**



### 4、高级编程语言 FORTRAN

1957 年， IBM发布高级编程语言 FORTRAN，开始被广泛应用。

平均来说，FORTRAN 写的程序，比等同的手写汇编代码短 20 倍，FORTRAN 编译器会把代码转成机器码。但它只能运行于IBM电脑中。



### 5、通用编程语言——COBOL

工业界，学术界，政府的计算机专家 在 1959 年组建了一个联盟，数据系统语言委员会（the Committee on Data Systems Languages），Grace Hopper 担任顾问。目的是**开发一种可以在不同机器上通用的编程语言**。

最后诞生了一门高级，易于使用的**"通用面向商业语言"**（Common Business-Oriented Language），简称 COBOL。为了兼容不同底层硬件，每个计算架构需要一个 COBOL 编译器，最重要的是，这些编译器都可以接收相同 COBOL 代码，不管是什么电脑，这叫**"一次编写，到处运行"**（write once, run anywhere）。如今大多数编程语言都是这样，不必接触 CPU 特有的汇编码和机器码，减小了使用门槛。

### 6、现代编程语言:1960s-2000

1960s 起，编程语言设计进入黄金时代。

1960 年代：ALGOL，LISP，BASIC  
1970 年代：Pascal，C，Smalltalk  
1980 年代：C++，Objective-C，Perl  
1990 年代：Python，Ruby，Java  

新千年 ：Swift, C#, Go 

### *7、安全漏洞&补丁由来：

在 1940 年代，程序输入通过打孔纸带。程序出现了问题（也就是漏洞），为了节约时间，只能贴上胶带也就是打补丁来填补空隙，漏洞和补丁因此得名。


## 第 12 集：编程基础 - 语句和函数  
 变量, 赋值语句  
 if 判断  
while 循环  
for 循环  
函数 


## 第 13 集：算法入门  
**0、基本慨念**

 算法（algorithm）：解决问题的基本步骤

**1、选择排序**

算法复杂度是O（n*n）

**2、大O表示法**

算法的输入规模和运行步数之间的关系，叫算法的 复杂度（complexity of the algorithm），表示运行速度的量级


计算机科学家们把算法复杂度叫 ，大 O 表示法（"big O notation"）

**3、归并排序**

归并排序的算法复杂度为O（n*log n），n是需要比较+合并的次数，和数组大小成正比，log n是合并步骤所需要的的次数。归并排序比选择排序更有效率。

**4、图搜索-Dijkstra算法**

一开始复杂度为O(n²)，后来复杂度为O（n log n +I），n表示节点数，I表示有多少条线。


## 第 14 集：数据结构  
 不同数据结构适用不同场景 

### 1、数组 

数组（Array），也叫列表（list）或向量（Vector），是一种数据结构。为了拿出数组中某个值，我们要指定一个下标（index），大多数编程语言里，数组下标都从 0 开始，用方括号 [ ] 代表访问数组。注意：很容易混淆 "数组中第 5 个数" 和 "数组下标为 5 的数"，数组下标为5的数是数组里面的第6个数。

### 2、字符串

字符串（String），即字母,数字,标点符号等组成的数组，字符串在内存里以0（二进制值0，null）结尾。

### 3、矩阵

矩阵（Matrix）是数组的数组。任何维度都行

### 4、结构体

 把几个有关系的变量存在一起叫做结构体（ Struct）

存结构体的数组，和其它数组一样，创建时就有固定大小，不能动态增加大小。还有，数组在内存中按顺序存储，在中间插入一个值很困难，但结构体可以创造更复杂的数据结构，消除这些限制。

### 5、指针

指针（Pointer ）是一种特殊变量，指向一个内存地址。

### 6、节点

以指针为变量的结构体叫节点(node)。

### 7、链表

用节点可以做链表（linked list），链表是一种灵活数据结构，能存很多个节点 (node)，灵活性是通过每个节点 指向 下一个节点实现的。链表可以是循环的也可以是非循环的，非循环的最后一个指针是0（null，代表链表尽头）

数组大小需要预先定好，而链表大小可以动态增减。可以创建一个新节点，通过改变指针值，把新节点插入链表，链表也很容易重新排序，两端缩减，分割，倒序等。

因为灵活，很多复杂数据结构 都用链表，最出名的是 队列（queue）和 栈（stack）

### 8、队列

"队列"（queue） 先进先出（FIFO——first in first out），"出队"（dequeue），"入队"（enqueue）。

### 9、栈

"栈"（Stack ）后进先出(LIFO)，"入栈"（push） "出栈"（pop）

### 10、树

Tree

二叉树 - Binary Tree  

 红黑树 red-black trees

###  11、图    

如果数据随意连接，有循环，我们称之为图（Graph  ）

### 12、堆


## 第 15 集：阿兰·图灵  


### 0.可判定性问题

是否存在一种算法，输入正式逻辑语句，输出准确的"是"或"否"答案？

1、1935年，美国数学家阿隆佐·丘奇，开发了一个叫"**Lambda 算子**"的数学表达系统，证明其不存在。虽然"Lambda 算子"能表示任何计算，但它使用的数学技巧难以理解和使用。

2、图灵机

同时，阿兰·图灵提出了一种假想的计算机“**图灵机**”，图灵机提供了简单又强大的数学计算模型。虽然用的数学不一样，但图灵机的计算能力和 Lambda 算子一样，同时因为图灵机更简单，所以在新兴的计算机领域更受欢迎。

图灵机是一台理论计算设备，有一个状态变量，保存当前状态，还有一组规则，描述机器做什么。规则是根据 当前状态+读写头看到的符号，决定机器做什么，结果可能是在纸带写入一个符号，或改变状态，或把读写头移动一格。

图灵证明了这个简单假想机器，如果有足够时间和内存，可以执行任何计算，它是一台**通用计算机**，只要有足够的规则，状态和纸带  可以创造任何东西。

事实上，就可计算和不可计算而言，没有计算机比图灵机更强大。和图灵机一样强大的，叫 "**图灵完备"**（Turing complete）

3.停机问题

为了回答可判定性问题图灵把图灵机用于一个有趣计算问题：**"停机问题"**，简单说就是，"给定图灵机描述和输入纸带，是否有算法可以确定 ，机器会永远算下去还是到某一点会停机？

图灵通过一个巧妙逻辑矛盾证明了停机问题是无法解决的。想象有一个假想图灵机，输入：问题的描述 + 纸带的数据。输出 Yes 代表会"停机"，输出 No 代表不会。图灵用 H 设计了另一个图灵机，实质上是一台和 H 输出相反的机器。如果程序不停机，另一台就停机，如果程序停机，另一台就永远运行下去。我们还需要在机器前面加一个**分离器**（splitter ），让机器只接收一个输入，这台新机器叫 **异魔**（Bizzaro）。这是一个悖论，意味着"停机问题"不能用图灵机解决。

**图灵证明了图灵机可以实现任何计算，"停机问题"证明了不是所有问题都能用计算解决。**

4、丘奇和图灵证明了计算是有极限的，起步了可计算性理论，现在叫"丘奇-图灵论题"。

### 1.破解德军英格玛加密机 

图灵是密码学之父

### 2.图灵测试

图灵提出 ，如果计算机能欺骗人类相信它是人类，才算是智能。

向人和机器同时发信息，收到的回答无法判断哪个是人，哪个是计算机，则计算机达到了智能程度。

图灵测试的现代版叫"公开全自动图灵测试，用于区分计算机和人类"（a completely automated public turing test to tell computers and humans apart），简称**"验证码"**（Captcha），防止机器人发垃圾信息等


## 第 16 集：软件工程  
- readme,07:33  版本控制   Version control  
  08:50  质量控制   Quality Assurance testing，QA  
  09:21  Beta, Alpha  


"软件工程"这个词由工程师 Margaret Hamilton 创造，她帮助 NASA 在阿波罗计划中避免了严重问题。


她曾说过："有点像牙根管治疗：你总是拖到最后才做 ，但有些事可以预先做好。有点像预防性体检, 只不过是预防软件出错"

### 1、对象

当任务庞大，函数太多，我们需要把函数打包成层级，把相关代码都放一起，打包成**对象**（object）。对象可以包括其他对象，函数和变量。

### 2、面向对象编程

把函数打包成对象的思想叫 "面向对象编程"（Object Oriented Programming），通过封装组件，隐藏复杂度。

### 3、API

当团队接收到子团队编写的对象时，需要文档（document）和程序编程接口（Application Programming Interface，API）来帮助合作。API控制哪些函数和数据让外部访问，哪些仅供内部。

### 4、集成开发环境（Integrated Development Environments  ，IDE）

程序员用来专门写代码的工具。

所有 IDE 都有写代码的界面，还带一些有用功能，比如代码高亮，来提高可读性。大型项目有很多源代码文件,IDE 帮助开发者整理和看代码.

许多 IDE 提供实时检查，比如拼写。


很多 IDE 还可以直接编译和运行代码.如果程序崩了，因为你还没写完呢,IDE 可以定位到出错代码,还会提供信息 帮你解决问题


### 5、调试（debug）

IDE帮你检查错误，并提供信息，帮你解决问题，这个过程叫调试

### 6、文档与注释

文档（readme）一般放在一个叫做README的文件里，文档也可以直接写成“注释”，放在源代码里。文档可以提高复用性。

注释（ comment  ）是标记过的一段文字，编译代码时，注释会被忽略。注释的唯一作用是帮助开发者理解代码。



### 7、版本控制

版本控制（version control），又称源代码管理（Source Control）。大型软件公司会把会把代码放到一个中心服务器上，叫"代码仓库"（code repository）。

程序员想改一段代码时，可以 check out，然后开发者在自己的电脑上编辑代码，加新功能，测试。修改更新完成后，可以把代码放回去，这叫  提交 (commit)。当代码被 check out，而且可能被改过了，其他开发者不会动这段代码，防止代码冲突和重复劳动，这样多名程序员可以同时写代码，建立庞大的系统。

存储在服务器的代码的主版本 (master)，应该总是编译正常，尽可能少 bug。但有时 bug 还是会出现，幸运的是，源代码管理可以跟踪所有变化，如果发现 bug，全部或部分代码，可以"回滚"到之前的稳定版。"源代码管理" 也记录了谁改了什么代码。



### 8、测试

测试可以统称 **"质量保证测试"**，简称 QA，严格测试软件的方方面面，模拟各种可能情况，看软件会不会出错，基本上就是找 bug。


解决大大小小的错误需要很多工作，但对确保软件质量至关重要，让软件在各种情况下按预期运行

### 9、beta alpha

beta版软件，即是软件接近完成，但没有完全被测试过，公司有时会向公众发布beta版，以帮助发现问题。

alpha是beta前的版本，一般很粗糙，只在内部测试




## 第 17 集：集成电路与摩尔定律  
### 1、分立元件与数字暴政

大约 1940年代~1960年代中期这段时间里，计算机都由独立部件组成，叫"**分立元件"**（discrete components），不同组件再用线连在一起，这会导致计算机的构成很复杂，这个问题叫做**数字暴政**。

### 2、集成电路与仙童半导体

封装复杂性：与其把多个独立部件用电线连起来，拼装出计算机，不如把多个组件包在一起，变成一个新的独立组件。这种新的独立组件就叫**集成电路**（Integrated Circuits，IC）。

仙童半导体（用硅做成）让集成电路变成了现实。为了不用焊接或用一大堆线，发明了**印刷电路板**（printed circuit board，PCB），PCB 可以大规模生产，无需焊接或用一大堆线。它通过蚀刻金属线的方式，把零件连接到一起。

把 PCB 和 IC 结合使用，可以大幅减少独立组件和电线，但做到相同的功能，而且更小，更便宜，更可靠.

### 3、光刻0421

光刻（Photolithography），即用光把复杂图案印到材料上。

把一片薄片状的硅叫做**晶圆**（Wafer ），通过一系列生产步骤，将晶圆表面薄膜的特定部分除去的工艺叫做**光刻**。

![e17-Photolithography](E:\自我提升\计算机科学速成课\image\e17-Photolithography.jpg)

半导体硅有时导电，有时不导电，我们可以控制导电时机，所以硅是做晶体管的绝佳材料。

在硅片顶部，加一层薄薄的氧化层, 作为保护层。

然后加一层特殊化学品, 叫 "光刻胶" ，光刻胶被光照射后，会变得可溶,可以用一种特殊化学药剂洗掉。

光掩膜上有要转移到晶圆上的图案，用强光照射 。挡住光的地方，光刻胶不会变化，光照到的地方，光刻胶会发生化学变化 。

洗掉光刻胶之后，暴露出氧化层。用另一种化学物质 - 通常是一种酸可以洗掉"氧化层"露出的部分, 蚀刻到硅层。

现在硅又露出来了，我们想修改硅露出来的区域 ，让它导电性更好，所以用一种化学过程来改变它，叫"**掺杂**"（doping）。"掺杂" 通常用高温气体来做，比如磷 ，渗透进暴露出的硅，改变电学性质。

我们还需要**几轮光刻法**来做晶体管，过程基本一样。先盖氧化层，再盖光刻胶，然后用新的图案不同的光掩膜， 在掺杂区域上方开一个缺口，洗掉光刻胶，然后用另一种气体掺杂 ，把一部分硅转成另一种形式。


最后一步，**在氧化层上做通道** ， 这样可以用细小金属导线，连接不同晶体管，再次用光刻胶和光掩膜，蚀刻出小通道。


现在用新的处理方法 叫"**金属化**" ，放一层薄薄的金属，比如铝或铜。但我们不想用金属盖住所有东西 ，我们想蚀刻出具体的电路，所以又是类似的步骤 ，用光刻胶+光掩膜，然后溶掉暴露的光刻胶，暴露的金属。

![e17-bipolar junction transistor](E:\自我提升\计算机科学速成课\image\e17-bipolar junction transistor.png)

晶体管终于做好了！它有三根线，连接着硅的三个不同区域，每个区域的掺杂方式不同，这叫双极型晶体管

![e17-smaller](E:\自我提升\计算机科学速成课\image\e17-smaller.png)

### 4、摩尔定律

戈登·摩尔看到了趋势：每两年左右，得益于材料和制造技术的发展 ，同样大小的空间，能塞进两倍数量的晶体管！

晶体管越小，要移动的电荷量就越少， 能更快切换状态 、耗电更少。电路更紧凑还意味着信号延迟更低 ， 导致时钟速度更快。

1970年代开始，超大规模集成(VLSI)软件自动生成芯片设计，用比如 "逻辑综合" 技术 ，可以放一整个高级组件，比如内存缓存。软件会自动生成电路，做到尽可能高效。许多人认为这是计算 4.0 的开始。

### 5、进一步小型化会碰到的问题

1、用光掩膜把图案弄到晶圆上，由于光的波长限制，精度已到极限。

2、量子隧穿效应：当晶体管非常小，电极之间可能只距离几个原子，电子会跳过间隙，会产生漏电问题


## 第 18 集：操作系统  



### 1、操作系统( Operating systems，OS)

1940,1950 年代的电脑，每次只能运行一个程序。程序员在打孔纸卡上写程序，然后拿到一个计算机房间,  交给操作员。等计算机空下来了，操作员会把程序放入，然后运行，输出结果，停机。

以前计算机慢，这种手动做法可以接受，但计算机速度指数级增长。很快，放程序的时间比程序运行时间还长。我们需要一种方式 **让计算机自动运作**，于是"操作系统"诞生了

操作系统也是一种程序，不过它有操作硬件的特殊权限，可以运行和管理其他程序。操作系统一般是开机第一个启动的程序，其他所有程序 都由操作系统启动。

### 2、批处理（batch processing）

之前只能一次给一个程序，现在可以一次多个。

当计算机运行完一个程序，会**自动运行下一个程序**，这叫 批处理。



### 3、外部设备（peripheral）

和计算机连着的其他设备，如打印机。

计算机变便宜变多，有不同配置的外部设备。

和早期的外部设备交互，是非常底层的，程序员要了解设备的硬件细节。加重问题的是，程序员很少能拿到所有型号的设备来测代码。所以一般是阅读手册来写代码，祈祷能正常运行，现在是"即插即用"，以前是"祈祷能用"。



### 4、设备驱动程序（Device drivers）

为了程序员写软件更容易，操作系统充当软件和硬件之间的媒介，更具体地说，操作系统提供 API 来抽象硬件，叫"设备驱动程序"。

程序员可以用标准化机制和输入输出硬件（I/O）交互。比如，程序员只需调用 print(highscore)，操作系统会处理  输到纸上的具体细节。



### 5、多任务处理（multitasking）

操作系统能使多个程序在单个CPU上同时进行的能力，叫做“多任务处理”

Atlas在单个 CPU 上同时运行几个程序，它通过**调度**（clever scheduling）来做到这一点。当某一程序要打印，因为打印机比 CPU 慢，与其等着它完成操作，Atlas 会把程序休眠，运行另一个程序。最终, 打印机会告诉 Atlas, 打印已完成，Atlas 会把程序标记成可继续运行。之后在某时刻会安排给 CPU 运行，并继续 print 语句之后的下一行代码，这样, Atlas 可以在 CPU 上运行一个程序，同时另一个程序在打印数据，同时另一个程序读数据。

### 6、虚拟内存（Virtual Memory ） 

同时运行多个程序的问题：每个程序都会占一些内存，当切换到另一个程序时，我们不能丢失数据。

解决办法： 给每个程序分配专属内存块，如果一个程序请求更多内存，操作系统会决定是否同意。这种灵活性很好，但带来一个奇怪的后果，程序 A 可能会分配到非连续的内存块。真正的程序可能会分配到内存中数十个地方，这对程序员来说很难跟踪。

为了隐藏这种复杂性，操作系统会把内存地址进行 **"虚拟化"**。这叫 "虚拟内存"（Virtual Memory），程序可以假定内存总是从地址0开始，简单又一致，而实际物理位置  被操作系统隐藏和抽象了。操作系统会自动处理 虚拟内存和物理内存之间的映射

虚拟内存的机制使程序的内存大小可以灵活增减，叫做**“动态内存分配**”（Dynamic memory allocation）。对程序来说，内存看上去是连续的。它简化了一切，为操作系统同时运行多个程序 提供了极大的灵活性。

### 7、内存保护（Memory Protection）

给每个程序分配单独的内存，那当这个程序出现混乱时，它不会影响到其他程序的内存，同时也能有效地防止恶意程序篡改其他程序，这叫做内存保护。

### 8、多用户分时操作系统（Multics）

计算机不仅能同时运行多个程序，还能让多用户能同时访问。多个用户用"**终端**"（terminal）来访问计算机，"终端"只是键盘+屏幕，连到主计算机，本身没有处理能力。这时操作系统不但要处理多个程序，还要处理多个用户。

为了确保其中一个人 不会占满计算机资源，开发了分时操作系统，意思是 每个用户只能用一小部分处理器，内存等。

### 9、Unix

Unix把操作系统分成两个部分，一个是操作系统的核心部分，如内存管理，多任务和输入/输出处理，这叫做**“内核**”（kernel），第二部分是一堆有用的工具，比如程序和运行库。

 "内核恐慌"（kernel panic）：如果有错误发生，我们就让内核"恐慌"（panic）。内核如果崩溃，没有办法恢复，所以调用一个叫"恐慌"（panic）的函数，起初只是打印"恐慌"一词，然后无限循环。需要重启解决

### 10、现代操作系统

Mac OS X, Windows 10, Linux, iOS and Android.


虽然大部分设备只有一个人使用，操作系统依然有"多任务, "虚拟内存", "内存保护"，因此可以同时运行多个程序。


## 第 19 集：内存&amp;储存介质  
​     

### 1、打孔纸卡/打孔纸带（Paper punch cards）

优点：不用电，便宜耐用

问题：读取慢 难修改 难存临时值

### 2、延迟线存储器（Delay Line Memory）

利用线的延迟在线里存储数据，又叫**顺序存储器**(sequential memory )或者**循环存储器**(cyclic-access memory)。

存在问题：

1 .每一个时刻只能读一位 (bit) 数据,不能随意调出数据

2.难以增加内存密度

### 3、磁芯存储器(magnetic core memory)

利用电磁感应原理：磁化的方向（极性）和电流方向相关，关掉电流磁性保持

优点：磁芯存储器能随时访问任何一位(bit)

问题 成本高

![e19-magnetic core memory](E:\自我提升\计算机科学速成课\image\e19-magnetic core memory.jpg)

### 3、磁带（Magnetic Tape）

磁带是纤薄柔软的一长条磁性带子 ，卷在轴上，可以在"磁带驱动器"内前后移动。里面有一个"写头"绕了电线，电流通过产生磁场，导致磁带的一小部分被磁化，电流方向决定了极性，代表 1 和 0。还有一个"读头"，可以非破坏性地检测极性.

![](E:\自我提升\计算机科学速成课\image\e19-Magnetic Tape.png)

优点 虽然磁带驱动器很贵，但磁带又便宜又小，因此磁带至今仍用于存档

问题 访问速度慢 磁带是连续的，必须倒带或快进到达特定位置，可能要几百英尺才能得到某个字节(byte)，这很慢

### 4、磁鼓（Magnetic Drum Memory ）

原理与磁带相似

有金属圆筒，盖满了磁性材料以记录数据，滚筒会持续旋转，周围有数十个读写头，等滚筒转到正确的位置\N 读写头会读或写 1 位(bit) 数据，为了尽可能缩短延迟, 鼓轮每分钟上千转！

### 5、（机械）硬盘（ Hard Disk Drives  ）

原理与磁鼓相似

磁盘表面有磁性，写入头和读取头 可以处理上面的 1 和 0
优点 薄，可以叠在一起，提供更多表面积来存数据

### 6、内存层次结构(Memory Hierarchy )

在计算机中，高速昂贵和低速便宜的内存混合使用以在成本和速度间取得一个平衡

一小部分高速+昂贵的内存,一部分稍慢+相对便宜些的内存,还有更慢+更便宜的内存

![e19-Memory Hierarchy ](E:\自我提升\计算机科学速成课\image\e19-Memory Hierarchy .jpg)

### 7、软盘（ Floppy Disk ）

除了磁盘是软的，其他都和硬盘一样，好处是便携，如今当杯垫挺不错的

### 8、光盘（Compact Disk ，CD）

原理：光盘表面有很多小坑，造成光的不同反射，光学传感器会捕获到，并解码为 1 和 0

### 9、固定硬盘（ Solid State Drives,SSD）      

没有机械活动部件，如U盘里面是集成电路

由于 SSD 没有移动部件，磁头不用等磁盘转，所以 SSD 访问时间低于 1/1000 秒



## 第 20 集：文件系统  



### 0、为什么要采用文件格式（file format）

文件在底层都是一样的，一长串二进制**。可以随便存文件数据，但按格式存会更方便，**为了知道文件是什么，文件格式至关重要。



### 1、 TXT 文本文件

存储文字，用ASCII解码

### 2、WAV 音频文件

存储音频数据，记录的是振幅（和声压成正比），每秒上千次的音频采样，模数转换，数模转换 

在正确读取数据前，需要知道一些信息，比如码率(bit rate)，以及是单声道还是立体声。
关于数据的数据，叫"元数据"(meta data)元数据存在文件开头，在实际数据前面，因此也叫 文件头(Header)

![e20-metadate](E:\自我提升\计算机科学速成课\image\e20-metadate.jpg)

### 3、 BMP 图片文件

位图(Bitmap)，后缀 .bmp, 存图片

记录每个像素的红绿蓝 RGB 值

BMP 文件开头也是元数据 ，有图片宽度，图片高度，颜色深度



### 4、目录文件

储存器没有文件的概念，只是存储大量位。所以为了存多个文件 ，需要一个特殊文件，记录其他文件的位置，比如开头，结尾，创建时间等，泛称目录文件（Directory File），目录文件经常存在开头，方便查找。

目录文件里，存所有其他文件的名字，格式是文件名 + 一个句号 + 扩展名，。目录文件还存文件的元数据，比如创建时间，最后修改时间，文件所有者，是否能读/写 ，最重要的是，目录文件有文件起始位置和长度。

如果要添加文件，删除文件，更改文件名等，必须更新目录文件





### 5、平面文件系统 - Flat File System

文件系统专门负责管理文件

平面文件系统中，文件都在同一个层次，早期空间小，只有十几个文件，平面系统够用

1. 解决文件紧密的排序造成的**前面的文件加一点数据 覆盖掉后面的一部分**的问题

 \1. 把空间划分成一块块，留有一些 "预留空间" 可以方便改动，同时方便管理（用这样的方案，目录文件要记录文件在哪些块里）

 \2. 文件拆分存在多个块里，我们不想覆盖掉隔壁的块，所以文件系统会分配 一个没使用的块，容纳额外的数据（目录文件会记录不止一个块，而是多个块）

假设想删掉一个文件，只需要在目录文件删掉那条记录，让一块空间变成了可用。注意这里没有擦除数据，只是把记录删了。之后某个时候，那些块会被新数据覆盖 ，但在此之前，数据还在原处，所以计算机取证团队可以"恢复"数据。

### 6、碎片整理（defragmentation）

文件被隔开在 不同块里，顺序也是乱的，这叫碎片。

文件的增删改查会不可避免的造成文件散落在各个块里，如果是磁带这样的存储介质就会造成问题，所以需要碎片整理——计算机把文件内容调换位置。

###  7、分层文件系统 - Hierarchical File System：

有不同文件夹，文件夹可以层层嵌套。

目录文件不仅要指向文件, 还要指向目录，我们需要额外元数据 来区分开文件和目录。
根目录在最顶层，所有其他文件和文件夹，都在根目录下。

除了能做无限深度的文件夹 ，这个方法也让我们可以轻松移动文件，如果想把块5的 theme.wav 从根目录移到音乐目录，不用移动任何数据块，只需要改两个目录文件 ， 一个文件里删一条记录，另一个文件里加一条记录。theme.wav 依然在块5。


## 第 21 集：压缩  




### 0.压缩的好处

压缩（compression）能使文件变小能存更多文件，传输也更快

### 1.游程编码 Run-Length Encoding

用于减少重复冗余的信息，适合经常出现相同值的文件。如果重复信息不多，有时候数据反而会变多。

比如一个图片，有7个连续黄色像素，与其全存下来：黄色，黄色，黄色...可以插入一个额外字节，代表有7个连续黄色像素，然后删掉后面的重复数据。为了让计算机能分辨哪些字节是"长度" ，哪些字节是"颜色" ， 格式要一致，所以我们要给所有像素前面标上长度。

这种压缩方式，我们没有损失任何数据 ，叫**"无损压缩"（Lossless compression）**

### 2.霍夫曼树 Huffman Tree和字典编码 Dictionary coders

用更紧凑的表示方式，出现频率高的用短的二进制表示，频率低的可用长的二进制。（离散里的最优生成树、前缀码）

除了替换后的二进制码，字典（压缩前后一一对应的编码）也要保存下来

无损压缩

### 3.感知编码 Perceptual coding

删掉人类无法感知的数据的有损压缩方法，叫做“感知编码”.虽然是有损压缩，但几乎不影响体验。

1、音频文件

人类听不到超声波，所以可以舍去。

MP3就是音频的一种压缩形式。

日常生活中你会经常碰到这类音频压缩，所以你在电话里的声音 和现实中不一样，压缩音频是为了让更多人能同时打电话
如果网速变慢了，压缩算法会删更多数据，进一步降低声音质量。

2、图像文件

"有损压缩图像格式"中，最著名的是 JPEG


就像听力一样，人的视觉系统也不是完美的。我们善于看到尖锐对比，比如物体的边缘，但我们看不出颜色的细微变化

JPEG 利用了这一点，把图像分解成 8x8 像素块，然后删掉大量高频率空间数据。

### 4.时间冗余 Temporal redundancy


利用了帧和帧之间的相似性，视频里不用每一帧都存所有像素 ，当帧和帧之间有小小的差异时，可以只存变了的部分。

更高级的视频压缩格式 会更进一步，找出帧和帧之间相似的补丁 ，然后用简单效果实现，比如移动和旋转，变亮和变暗。

但用补丁的移动和旋转 来更新画面，当压缩太严重时会出错。 没有足够空间更新补丁内的像素，即使补丁是错的，视频播放器也会照样播放，导致一些怪异又搞笑的结果。

MPEG-4 是视频压缩的常见标准。




## 第 22 集：命令行界面  
**人机交互 （Human-Computer Interaction）发展史**



1、1820 年代，早期机械计算设备在交互界面用齿轮，旋钮和开关等机械结构来输入输出。不算运行时间，输入一个程序可能要几星期。运行完毕后想拿出数据，一般是打印到纸上。

2、1850年代，用纸卡/纸带输入程序和数据，运行开始直到结束，中间没有人类进行操作。原因是计算机很贵，不能等人类慢慢输入，执行完结果打印到纸上。

3、

到1950年代晚期，计算机足够便宜+快，人类和计算机交互式操作变得可行。

计算机需要某种方法来获得用户输入。早期计算机用了一种特殊打字机，是专门用来发电报的,叫 电传打字机（ a teletype machine）。这些打字机是强化过的，可以用电报线发送和接收文本，按一个字母，信号会通过电报线，发到另一端。另一端的电传打字机会打出来，使得两人可以长距离沟通，因为电传打字机有电子接口，稍作修改就能用于计算机。

现代打字机，即键盘（keyboard）。当时设计的QWERTZ 布局（我们用的也是这种）沿用至今，但布局不是唯一的，也有国家用别的布局。

电传交互界面在 1960~1970 很常见。输入一个命令，按回车，然后计算机会输回来，用户和计算机来回"对话"，这叫**"命令行界面"（command line interfaces）**，它是最主要的人机交互方式，一直到 1980 年代。



4、到1970年代末，屏幕成本足够低，屏幕代替电传打字机变得可行。与其为屏幕  专门做全新的标准，工程师直接用现有的 电传打字机协议，屏幕就像无限长度的纸 ， 除了输入和输出字，没有其它东西。协议是一样的，所以计算机分不出是纸还是屏幕，这些"虚拟电传打字机"（virtual teletype）或"玻璃电传打字机"（glass teletype）叫 终端（terminals）。






## 第 23 集：屏幕与 2D 图形显示  


### 0、PDP-1 计算机

1960 年的 PDP-1是一个早期图形计算机的好例子。电脑、电传打字机（键盘）和屏幕{显示器）分开，因为当时文本任务和图形任务是分开的。


事实上，早期的屏幕无法显示清晰的文字，典型用途 是跟踪程序的运行情况，比如寄存器的值。如果用打印机 ，不仅费纸而且慢，而屏幕更新很快，对临时值简直完美。而打印到纸上，有更高的对比度和分辨率，用于输出计算结果。





### 1、 阴极射线管 Cathode Ray Tube (CRT)

原理：把电子发射到 有磷光体涂层的屏幕上，当电子撞击涂层时 会发光几分之一秒。由于电子是带电粒子，路径可以用磁场控制，屏幕内用板子或线圈  把电子引导到想要的位置。



 CRT 有两种绘图方式：

1）引导电子束描绘出形状：**矢量扫描** Vector Scanning

![e23-vector scanning](E:\自我提升\计算机科学速成课\image\e23-vector scanning.png)

2）2. 按固定路径，一行行来 ， 从上向下，从左到右，不断重复：**光栅扫描** Raster Scanning

![e23-raster scanning](E:\自我提升\计算机科学速成课\image\e23-raster scanning.png)

### 2、 液晶显示器 Liquid Crystal Displays (LCD)

因为显示技术的发展，我们终于可以在屏幕上显示清晰的点，叫"像素" (Pixel)

液晶显示器，和以前的技术相当不同，但 LCD 也用光栅扫描， 每秒更新多次 像素里红绿蓝的颜色

### 3、字符生成器 Character generator

相比于像素，为了减少内存，人们更喜欢使用字符。计算机需要额外硬件，来从内存读取字符，转换成**光栅**图形 ，这样才能显示到屏幕上，这个硬件叫 "字符生成器"，基本算是第一代显卡（graphics cards）。

字符生成器内部有一小块**只读存储器（Read Only Memory）**，存着每个字符的图形，叫**"点阵图案"（dot matrix pattern）**

为了显示，"字符生成器" 会访问内存中一块特殊区域，这块区域专为图形保留，叫 **屏幕缓冲区（Screen buffer）**。程序想显示文字时，修改这块区域里的值就行。

字符生成器 是一种省内存的技巧，但没办法绘制任意形状。

### 4、 矢量命令画图

为了绘制任意形状，同时不吃掉所有内存，计算机科学家用 CRT 上的"矢量模式"。

概念非常简单：所有东西都由线组成,这些矢量指令也存在内存中，通过矢量图形卡画到屏幕上，数百个命令可以按序存在屏幕缓冲区画出复杂图形。由于这些矢量都在内存中 ，程序可以更新这些值，让图形随时间变化 - 动画！



### 5、**Sketchpad**

1962 年是一个大里程碑 ， Sketchpad 诞生，一个交互式图形界面，用途是**计算机辅助设计** (Computer-Aided Design，CAD)，它被广泛认为是第一个完整的图形程序。

为了与图形界面交互 ，Sketchpad 用了当时发明不久的输入设备 光笔，就是一个有线连着电脑的触控笔。笔尖用光线传感器，可以检测到显示器刷新，通过判断刷新时间，电脑可以知道笔的位置，有了光笔和各种按钮， 用户可以画线和其他简单形状，Sketchpad 可以让线条完美平行，长度相同 、完美垂直90度，甚至动态缩放。用户还可以保存设计结果，方便以后再次使用 ，甚至和其他人分享。你可以有一整个库 ， 里面有电子元件和家具之类的，可以直接拖进来用。

Sketchpad 和光笔代表了人机交互方式的关键转折点，电脑不再是关在门后 负责算数的机器了，而是可以当助手，帮人类做事

### 6、**位图显示**（bitmapped displays）

内存中的位（bit）对应着屏幕上显示的像素，这叫位图显示。图形是一个巨大像素值矩阵通过完全的像素控制，我们可以绘制任意图形。

计算机把像素数据存在内存中一个特殊区域 ， 叫**"帧缓冲区"（frame buffer）**。早期时，这些数据存在内存里，后来存在高速视频内存（special high speed Video RAM）里，简称 VRAM。VAM 在显卡上，这样访问更快 ，如今就是这样做的。

程序可以操纵"帧缓冲区"中的像素数据，实现交互式图形。当然，程序员不会浪费时间从零写绘图函数，而是用预先写好的函数来做，画直线，曲线，图形，文字等。

位图的灵活性，为交互式开启了全新可能， 但它的高昂成本持续了十几年






## 第 24 集：冷战和消费主义  
冷战导致美国往计算机领域投入大量资源  



范内瓦·布什预见了计算机的潜力，提出假想机器 Memex  。这个设备可以存许多资料，而且数据是按照格式存储,所以可以快速查询，有很大灵活性，可以辅助我们的记忆。可以和别人沟通。他还预测会出现 新的百科全书形式信息之间相互链接（维基百科）。Memex 启发了  之后几个重要里程碑，比如伊万·萨瑟兰 的 Sketchpad(画板)，以及 Dough Engelbart 的 oN-LINE 系统
他还帮助建立 国家科学基金会，给科学研究提供资金。美国的科技领先全球，主要原因之一就是这个机构.



1950 年代消费者开始买晶体管设备，收音机大卖  
日本取得晶体管授权后，索尼做了晶体管收音机，为日本半导体行业崛起埋下种子



苏联 1961 年把宇航员加加林送上太空，导致美国提出登月 ，NASA 预算大大增加。

为了在太空中导航NASA 需要电脑计算复杂的轨道来引导太空船，因此，他们造了 "阿波罗导航计算机"。计算机要快, 要又小又轻.要超级可靠，所以他们采用全新技术：集成电路来制作登月计算机 



虽然人们经常把集成电路的发展 归功于阿波罗导航计算机，但阿波罗登月毕竟只有 17 次 ， 集成电路的发展实际上是由军事应用大大推进。美国造超级计算机进一步推进集成电路



美国半导体行业一开始靠政府高利润合同起步，由于利润小而忽略消费者市场。因此日本半导体行业在1950和1960年代靠低利润率占领了消费者市场。1970年代，太空竞赛和冷战渐消，行业开始衰败。  
很多公司倒闭，英特尔从内存集成电路（Memory IC）转型到处理器（processes）



美国公司的无力导致 夏普 和 卡西欧 这样的日本公司占领了1970年代的主流产品。


因为集成电路，计算机又小又便宜，手持计算器取代了办公室里昂贵的桌面计算器。便捷的手持计算机大卖，进一步降低了集成电路的成本，使得微处理器被广泛使用。

很快，日本电子产品到处都是，从电视到手表到随身听，而廉价的微处理器，也催生了全新的产品，比如街机游戏。

因为成本不断下降，很快，普通人也买得起计算机了，这段期间，第一批家用电脑开始出现，比如1975年的 Altair 8800，以及第一款游戏机，比如1977年的Atari 2600。



政府和消费者推动了计算机的发展，早期靠政府资金，让技术发展到足够商用，然后消费者购买商用产品继续推动产品发展。




## 第 25 集：个人计算机革命  
1970年代初成本下降，个人计算机变得可行

1、单芯片 CPU 的出现，强大 + 体积小 + 便宜/

2、集成电路的进步，也提供了低成本固态存储器，可以用于计算机的 RAM 和 ROM。忽然间 ，把整台计算机做到一张电路板上成为可能，大大地降低了制造成本

3、便宜可靠的储存介质 ，比如磁带和软盘

4、低成本的显示器 ，通常是电视机稍作改装而成

如果在 1970 年代 ，将这四种原料混在一起，就得到了"微型计算机"（microcomputer）。因为和那个时代的"普通"计算机相比这些计算机很小。



 Altair 8800：第一台取得商业成功的个人计算机  



比尔·盖茨 和 保罗·艾伦写 **BASIC 解释器**  

19岁和22岁的比尔·盖茨和保罗·艾伦联系了制造 Altair 8800 的 MITS 公司，建议说，如果能运行 BASIC 程序（一门更受欢迎更简单的编程语言） 会对爱好者更有吸引力。为此，他们需要一个程序 把 BASIC 代码转成可执行机器码的 解释器 (interpreter)。"解释器"和"编译器"类似，区别是"解释器"运行时转换，而"编译器"提前转换。

MITS 同意在计算机上搭载他们的软件，Altair BASIC 成了微软的第一个产品。



乔布斯提议卖组装好的计算机，Apple-I 诞生  

计算机爱好小组是"家酿计算机俱乐部"第一次小组聚会在1975年3月，看一台第一批运来加州的 Altair 8800。

第一次聚会上，24岁的 Steve Wozniak 被 Altair 8800 大大激励，开始想设计自己的计算机。1976年5月，他向小组展示了原型机，并且把电路图分享给感兴趣的其他会员，他的设计不同寻常 \N 要连到电视显示，并提供文本界面。


同是俱乐部成员和大学朋友的 史蒂夫·乔布斯，建议说与其免费分享设计，不如直接出售装好的主板，它叫 Apple-I ，苹果计算机公司的第一个产品



1977年出现3款开箱即用计算机：  &quot;Apple-II&quot;，&quot;TRS-80 Model I&quot;，&quot;Commodore PET 2001&quot;  

这3台计算机被称为1977年的"三位一体"，它们都自带了 BASIC 解释器，让不那么精通计算机的人也能用 BASIC 写程序

苹果公司第一个提供全套设备的产品，设计和制造工艺都是专业的，它还提供了简单彩色图形和声音输出，这些功能对低成本机器非常了不起。Apple-II 卖了上百万套，把苹果公司推到了个人计算机行业的前沿。



针对消费者的软件行业 开始腾飞，市场上出现了各种 \N 针对个人计算机的游戏和生产力工具。

比如计算器和文字处理器，最火的是 1979 年的 VisiCalc，第一个电子表格程序，是微软 Excel 和 Google Sheets 的老祖先。



IBM 意识到个人计算机市场  

一个由十二名工程师组成的精干团队（后来叫"肮脏十二人"），被派往佛罗里达州的博卡拉顿（Boca Raton）办公室独立工作，不受 IBM 内部的政治斗争干扰 ，他们想怎么设计怎么设计。没用 IBM 的 CPU，选了 Intel 的芯片，也没用 IBM 的首选操作系统 CP/M，而是用了微软的 DOS，依此类推，从屏幕到打印机都这样自由选择。IBM 第一次不得不与外部公司竞争，来给新计算机做硬件和软件..这和 IBM 的传统做法不同：自己做硬件来节省成本,然后和其它公司合作.

IBM PC 发布，采用开放式架构，有良好的文档和扩展槽，使得第三方可以做硬件/外设，包括显卡，声卡，外置硬盘，游戏控制杆 ，以及无数其它组件，这刺激了创新，激发了竞争，产生了巨大的生态系统。这个开放架构叫 **IBM Compatible"（IBM 兼容）**，意味着如果买了"IBM兼容"的计算机，你可以用庞大生态系统中的其它软硬件。
生态系统产生雪球效应：  
因为用户多，软硬件开发人员更愿意花精力在这个平台  
因为软硬件多，用户也更乐意买 &quot;IBM 兼容&quot; 的计算机 

 

只有苹果在非  &quot;IBM 兼容&quot; 下保持了足够市场份额 ，苹果选**封闭架构**，一切都自己来，用户一般无法加新硬件到计算机中，意味着苹果公司要做自己的计算机，自己的操作系统，还有自己的外围设备，如显示器，键盘和打印机。通过控制整个范围，从硬件到软件，苹果能控制用户体验并提高可靠性。

为了在低成本个人计算机的竞争冲击下生存下来，苹果需要提高自身水平 ， 提供比 PC 和 DOS 更好的用户体验


他们的答案是于 1984 年发布Macintosh，一台突破性 价格适中的一体式计算机 ， 用的不是命令行界面，而是图形界面。




## 第 26 集：图形用户界面 (graphical user interface，GUI)  
——**GUI是“事件驱动编程”，代码可以在任意时间执行以响应事件，而不像传统代码一样自上而下。**



图形界面先驱：道格拉斯·恩格尔巴特（Douglas Engelbart）

恩格尔巴特受万尼瓦尔·布什 的 Memex 文章启发，在1962年的一份名为："增强人类智力"开创性报告中 ，汇集了各种想法。他构想计算机不仅做自动化工作，也可以成为未来知识型员工 应对复杂问题的工具。伊凡·苏泽兰 的"几何画板" \N 进一步启发了 恩格尔巴特。他开始招募团队来做 oN-Line System。

他意识到如果只有键盘  对他想搭建的程序来说是不够的。要和屏幕上的信息互动，用某种设备在屏幕上移动[光标]。1964年，和同事比尔·英格利希的共同努力下，他创造了第一个计算机鼠标，尾部有一根线。

1968年，恩格尔巴特  在"秋季计算机联合会议"展示了他的系统。这次演示 被视为如今所有演示的祖先，演示有90分钟 ，展现了现代计算机的许多功能：包括 位图图像、视频会议、文字处理、和 实时协作编辑文件、还有现代图形界面的原型 （比如鼠标和多窗口，不过窗口不能重叠）

这个"跨时代"最终在商业上失败了，但它对当时的计算机研究者影响巨大，恩格尔巴特 因此获得1997年图灵奖。



恩格尔巴特团队里的许多人，包括比尔·英格利希，去了施乐公司新成立的"帕洛阿尔托研究中心"（Xerox PARC）。他们在这里开发了第一台带真正 GUI 的计算机：Xerox Alto(施乐奥托) ，创立了桌面（desktop），窗口（window）等计算机概念。

窗口可以重叠，挡住后面的东西;还有桌面配件，比如计算器和时钟，用户可以把配件在屏幕上四处移动;它还提供了一套基本部件可复用的基本元素 , 比如按钮，打勾框，滑动条和标签页。
 Alto 团队用窗口（window），图标(icon)，菜单(menu)和指针(pointer)来设计界面，因此叫 **WIMP 界面**（WIMP interface）



1981年发布的 Xerox Star system(**施乐之星系统**)扩展了桌面隐喻，创建了文档概念。



**所见即所得 WYSIWYG**——施乐打印出来的东西和计算机上一样，并发明了剪切 复制 黏贴等计算机概念



史蒂夫·乔布斯去施乐参观。施乐公司主动找苹果，希望合作。在苹果备受瞩目的 首次公开募股(IPO) 前，施乐买了苹果的一百万美元股份

但一个额外条款是："公布一切施乐研究中心正在进行的酷工作"


其中有个演示是：一个清晰的位图显示器上，运行着施乐公司的图形界面 ，操作全靠鼠标直观进行。



史蒂夫和随行的工程师回到苹果公司，开始开发新功能-比如菜单栏和垃圾桶，垃圾桶存删除文件。苹果第一款有图形界面和鼠标的产品，是 1983 年发行的 Apple Lisa，因为太贵在商业上失败。

1984年苹果推出 Macintosh 成功



1985年推出 Windows 1.0，之后出到 3.1

1995年推出 Windows 95 ，提供新的图形界面，并有Mac没有的新功能，如多任务和受保护内存。Windows 95 引入了许多 如今依然见得到的 GUI 元素，比如开始菜单，任务栏和 Windows 文件管理器。

为了让桌面更简单友好，1995年微软推出 Microsoft Bob——类似于房子的设计，失败了


## 第 27 集：3D 图形  
### 1.线框渲染 Wireframe Rendering

有图形算法 负责把3D坐标"拍平"显示到2D屏幕上，这叫3D投影(3D Projection)，包括正交投影（Orthographic Projection）和透视投影（Perspective Projection）。

所有的点都从3D转成2D后，就可以用画2D线段的函数来连接这些点，这叫线框渲染。



### 2.网格 Mesh

如果我们需要画比立方体复杂的图形，三角形比线段更好，在3D图形学中我们叫三角形"多边形"(Polygons)，一堆多边形的集合叫 网格，网格越密，表面越光滑，细节越多，也意味着更多计算量。

**三角形更常用因为其简单性，任意三点能定义唯一的平面**

### 3. 扫描线渲染 Scanline Rendering

——填充图形的经典算法

![e27-scanline rendering](E:\自我提升\计算机科学速成课\image\e27-scanline rendering.PNG)

 填充的速度叫做**填充速率**（fillrate）



这样的三角形比较丑，边缘满是锯齿.当像素较小时 就不那么明显

**抗锯齿**（(Anti-aliasing)）——一种减轻锯齿的方法，边缘羽化，如果像素在多边形内部，就直接涂颜色，如果多边形划过像素，颜色就浅一些。抗锯齿被广泛使用，比如字体和图标.

![e27-Anti-aliasing](E:\自我提升\计算机科学速成课\image\e27-Anti-aliasing.PNG)

### 4.遮挡 Occlusion

最直接的处理方法：**排序算法**（类似图层），从远到近排列，然后从远到近渲染，这又叫**画家算法**



另一种画遮挡的方法：**深度缓冲 Z Buffering**

在内存里存一个数字矩阵，记录场景中每个像素和摄像机的距离。Z缓冲区完成后，会和"扫描线"算法的改进高级版配合使用，不仅可以勘测到线的交叉点，还可以知道某像素是否在最终场景中可见，如果不可见，扫描线算法会跳过那个部分。

![e27-Z Buffering](E:\自我提升\计算机科学速成课\image\e27-Z Buffering.png)

当两个多边形距离相同时，多边形会在内存中移来移去，访问顺序会不断变化，另外,计算浮点数有舍入误差。所以哪一个画在上面, 往往是不可预测的，导致出现 **Z-fighting** 效果 。 3D游戏中常见



### **5.背面剔除 Back Face Culling**

三角形有两面,正面和背面。由于游戏角色的头部或地面，只能看到朝外的一面。所以3D游戏为了节省处理时间，会忽略多边形背面，这很好,但有个bug是 如果进入模型内部往外看，头部和地面会消失。



### **6.灯光（lighting）/ 明暗处理（shading）**

在3D图形上任取一小个区域，它面对的方向叫**“表面法线”**（Surface Normal）

加个光源，因为面对的角度不同，反射到观察者的光线不同，每个多边形被照亮的程度不同，这叫**平面着色** （Flat Shading）。

这是基本的照明算法，缺点是使多边形边界明显，看上去不光滑。因此开发了更多算法，比如 **高洛德着色**（Gouraud Shading） 和 **冯氏着色**（Phong Shading），**不只用一种颜色给整个多边形上色**，而是以巧妙的方式改变颜色，得到更好的效果。



### **7.纹理（textures）**

纹理在图形学中指外观，而不是手感。

纹理有多种算法来达到花哨效果，最经典的是**纹理映射**（Texture Mapping）。

用"扫描线算法"填充时，多边形坐标和纹理坐标对应，可以看看内存内的纹理图像，决定像素用什么颜色。纹理算法会查询纹理，从相应区域取平均颜色，并填充多边形。

![e27-Texture Mapping](E:\自我提升\计算机科学速成课\image\e27-Texture Mapping.png)

### 8.图形处理单元 GPU, Graphics Processing Unit

加速渲染的方法：

1、为这种特定运算 做专门的硬件来加快速度，让运算快如闪电；

2、把3D场景分解成多个小部分，然后并行渲染，而不是按顺序渲染

CPU不是为此设计的，因此图形运算不快。所以，计算机工程师为图形做了专门的处理器 GPU "图形处理单元"。

GPU 在显卡上，周围有专用的 RAM，所有网格和纹理都在里，让 GPU 的多个核心可以高速访问。


## 第 28 集：计算机网络  
### 1. 局域网 Local Area Networks - LAN

第一个计算机网络出现在1950~1960年代，通常在公司或研究室内部使用。

好处：方便信息交换，比把纸卡或磁带送到另一栋楼里更快速可靠；能共享物理资源（与其每台电脑配一台打印机，大家可以共享一台联网的打印机）；早期网络也会共享存储空间，因为每台电脑都配存储器太贵了。



计算机近距离构成的小型网络叫**局域网**（ Local Area Networks）， 简称LAN

局域网能小到是同一个房间里的两台机器，或大到校园里的上千台机器。

### 2.**"以太网"**（Ethernet）

尽管开发和部署了很多不同 LAN 技术，其中最著名和成功的是**"以太网"**（Ethernet）  , 开发于1970年代 ， 在施乐的"帕洛阿尔托研究中心"诞生, 今日仍被广泛使用。

以太网的最简单形式是：一条以太网电线连接数台计算机。当一台计算机要传数据给另一台计算机时,它以电信号形式，将数据传入电缆。



因为电缆是共享的 ,连在同一个网络里的所有计算机都看得到数据,但无法判定数据是传给谁的。为了解决这个问题，以太网需要每台计算机有唯一的  **媒体访问控制地址**(Media Access Control address) ，简称 MAC地址.

这个唯一的地址放在头部，作为数据的前缀发送到网络中。所以，计算机只需要监听以太网电缆 ，只有看到自己的 MAC 地址，才处理数据。这运作得很好，现在制造的每台计算机都自带唯一的MAC地址,用于以太网和无线网络。



多台电脑共享一个传输媒介，叫做**载波侦听多路访问**（ Carrier Sense Multiple Access - CSMA）。载体(carrier)指运输数据的共享媒介.以太网的"载体"是铜线,  WiFi 的"载体"是传播无线电波的空气。很多计算机同时侦听载体,所以叫"侦听"和"多路访问"。而载体传输数据的速度 叫"带宽"。

使用共享载体的弊端:当网络流量较小时，计算机可以等待载体清空,然后传送数据。但随着网络流量上升，两台计算机想同时写入数据的概率也会上升，这叫**冲突**（collision） ，数据会全都乱套。

计算机能够通过监听电线中的信号检测这些冲突。最明显的解决办法是停止传输，等待网络空闲, 然后再试一遍。问题是其他计算机也打算这样做，其他等着的计算机可能在任何停顿间隙闯入，导致越来越多冲突。

因此，当计算机检测到冲突，就会在重传之前等待一小段时间（包括固定时间+随机时间），再次堵塞时固定时间将会指数级增加（1 2 4 8 16 ......），这叫做**指数退避**（ Exponential Backoff）。因为计算机的退避 ，冲突次数降低了，数据再次开始流动起来，网络变得顺畅。以太网和WiFi都用这种方法，很多其他传输协议也用。



为了减少冲突+提升效率，我们需要减少同一载体中设备的数量 ，载体和其中的设备总称 **"冲突域"**（Collision Domain）。

为了避免冲突，可以用**交换器**（switch）一个冲突域拆成两个冲突域。交换机位于两个更小的网络之间 ，在同一个小冲突域里的传输不会占用另一个冲突域的网络，必要时才在两个网络间传数据，此时两个网络都会被短暂占用。这叫 **电路交换** （Circuit Switching)



### 3.**"电路交换"**（Circuit Switching）

大型网络中，从一个地点到另一个地点通常有多条路线，这就带出了另一个话题 **路由**（routing）



连接两台相隔遥远的计算机或网路，最简单的办法 是**分配一条专用的通信线路**，早期电话系统就是这样运作的。

假设"印第安纳波利斯"和"米苏拉"之间，有五条电话线。如果在1910年代，John 想打电话给 Hank，工作人员手动将 John 的电话连到 \N 通往米苏拉的未使用线路。通话期间 这条线就被占用了 如果五条线都被占用了， John 要等待某条线空出来，这叫 **"电路交换"**（Circuit Switching），因为是把电路连接到正确目的地。


缺点：不灵活而且价格昂贵 因为总有闲置的线路

好处：有一条专属于自己的线路， 你可以最大限度地随意使用，无需共享。因此军队, 银行和其他一些机构依然会购买专用线路来连接数据中心




### 4. 报文交换 Message Switching

消息会经过好几个站点

报文的具体格式简称IP，每一个电脑都会有一个IP地址



消息沿着路由跳转的次数 叫"**跳数**"(hop count)。记录跳数很有用，因为可以分辨出路由问题。看到某条信息的跳数很高，说明出了路由故障，这叫**跳数限制**（Hop Limit）。



好处：可以用不同路由，通信更可靠也更能容错。

坏处：当报文比较大的时候，会堵塞网络，因为要把整个报文从一站传到下一站后才能继续传递其他报文。

解决方法： 将大报文分成很多小块，叫"**数据包**"（packets）来进行运输，这叫“**分组交换**”（Packet Switching ）。就像报文交换，每个数据包都有目标地址 ，因此路由器知道发到哪里。

报文具体格式由"互联网协议"定义，简称 IP ， 这个标准创建于 1970 年代。每台联网的计算机都需要一个IP地址。路由器会平衡与其他路由器之间的负载 ，以确保传输可以快速可靠，这叫"**阻塞控制**"（congestion control）。有时，同一个报文的多个数据包 ， 会经过不同线路，到达顺序可能会不一样，这对一些软件是个问题。幸运的是，在 IP 之上还有其他协议，比如 TCP/IP, 可以解决乱序问题。






## 第 29 集：互联网  
### 1.电脑连接互联网的过程

你所用的电脑首先要连接到**局域网**（家里WiFi路由器连着的所有设备，组成了局域网），局域网再连到**广域网（WAN）**，广域网的路由器一般属于你的**互联网服务提供商（ Internet Service Provider，ISP）**。广域网里，先连到一个区域性路由器，这路由器可能覆盖一个街区。然后连到一个更大的 WAN，可能覆盖整个城市。可能再跳几次，但最终会到达互联网主干再连更大的WAN，往复几次，最后连到互联网主干。互联网主干由一群超大型、带宽超高路由器组成。

### 2.IP - 互联网协议 - Internet Protocol

互联网是一个巨型分布式网络 ，会把数据拆成一个个数据包来传输。数据包（packet）想在互联网上传输， 要符合"互联网协议"（Internet Protocol，IP）的标准 。

IP 是一个非常底层的协议，负责**把数据包送到正确的计算机**。

数据包的头部（或者说前面）只有目标地址。这意味着当数据包到达对方电脑，对方不知道把包交给哪个程序。

![e29- Internet Protocol](E:\自我提升\计算机科学速成课\image\e29- Internet Protocol.png)

### 3. UDP - 用户数据报协议 - User Datagram Protocol

在 IP 之上，开发更高级的协议。这些协议里 ，最简单最常见的叫"用户数据报协议"，简称 UDP，UDP负责**把数据包传送到正确的程序**。

端口号（ port number ），每个想访问网络的程序， 都要向操作系统申请一个端口号。当一个数据包到达时 ，接收方的操作系统会读 UDP 头部，读里面的端口号。

校验和（checksum），用于检查数据是否正确，检查方式是把数据求和来对比。UDP 中，校验和"以 16 位形式存储 (就是16个0或1)
，如果算出来的和，超过了 16 位能表示的最大值 ， 高位数会被扔掉，保留低位。

![e29-User Datagram Protocol](E:\自我提升\计算机科学速成课\image\e29-User Datagram Protocol.jpg)

缺点：UDP **不提供数据修复或数据重发的机制**，接收方知道数据损坏后，一般只是扔掉。而且，发送方无法得知数据包是否到达。对有些程序不影响，但发邮件则不行。

优点：UDP 又简单又快。拿 Skype 举例 ，它用 UDP 来做视频通话，能处理坏数据或缺失数据。

### 4.TCP - 传输控制协议 - Transmission Control Protocol

如果要控制所有数据必须到达，就用传输控制协议。

TCP 和 UDP 一样，头部也在存数据前面，因此人们叫这个组合 TCP/IP。

就像 UDP ，TCP 头部也有"端口号"和"校验和"，但 TCP 有更高级的功能，我们这里只介绍重要的几个：

1. TCP 数据包**有序号**。序号使接收方可以把数据包排成正确顺序，即使到达时间不同
2. TCP 要求接收方的电脑收到数据包并且"校验和"检查无误后（数据没有损坏），给发送方发一个**确认码**（ACK），代表收到了。如果过了一定时间还没收到确认码， 发送方会再发一次。 数据包可能的确到了，只是确认码延误了很久，或传输中丢失了，但因为收件方有序列号，如果收到重复的数据包就删掉。得知上一个数据包成功抵达后，发送方会发下一个数据包。
3. TCP 不是只能一个包一个包发,可以同时发多个数据包，收多个确认码 ,这大大**增加了效率**，不用浪费时间等确认码。确认码的成功率和来回时间可以推测网络的拥堵程度。TCP 用这个信息，调整同时发包数量，**解决拥堵问题**


缺点：那些"确认码"数据包把数量翻了一倍。由于这个特点，TCP对时间要求高的程序不适用



### 5.DNS - 域名系统 - Domain Name System

计算机访问网站时需要**IP地址**和**端口号**，但记数字很难。所以互联网通过域名系统把域名和IP地址一一对应。

在浏览器里输 youtube.com ，浏览器会去问 DNS 服务器（一般是互联网供应商提供的），它的 IP 地址是多少。DNS 会查表，如果你乱敲键盘加个.com 然后按回车，你很可能会看到 DNS 错误，因为网站不存在。如果域名存在，就返回对应 IP 地址，然后浏览器会给这个 IP 地址发 TCP 请求，要网站数据。


如今有三千万个注册域名（二级域名），所以为了更好管理，DNS 不是存成一个超长超长的列表，而是存成**树状结构**。

顶级域名（TLD）在最顶部，下一层是二级域名，再下一层叫子域名

![e29-domain structure](E:\自我提升\计算机科学速成课\image\e29-domain structure.png)

这些数据散布在很多 DNS 服务器上，不同服务器负责树的不同部分。



### **6.OSI - 开放式系统互联通信参考模型 - Open System Interconnection**  

开放式系统互联通信参考模型(OSI) 的底下5层

线路里的电信号，以及无线网络里的无线信号,这些叫**"物理层"(Physical Layer)**

**"数据链路层"(Data Link Layer)**负责操控"物理层"，\N 数据链路层有：媒体访问控制地址（MAC addresses），碰撞检测(collision detection)，指数退避(exponential backoff)，以及其他一些底层协议。

**''网络层"( Network Layer)**，负责各种报文交换（switching）和路由（routing）

**传输层"（Transport layer）**：  UDP 和 TCP 这些协议,负责在计算机之间进行点到点的传输，而且还会检测和修复错误

**"会话层"（Session Layer）**使用 TCP 和 UDP 来创建连接，传递信息，然后关掉连接，这一整套叫"会话"，查询 DNS 或看网页时，就会发生这一套流程。



这个概念性框架 把网络通信划分成多层，每一层处理各自的问题。如果不分层 ，直接从上到下捏在一起实现网络通信，是完全不可能的。抽象使得科学家和工程师能分工同时改进多个层 ，不被整体复杂度难倒。

![e29-Open System Interconnection ](E:\自我提升\计算机科学速成课\image\e29-Open System Interconnection .png)


## 第 30 集：万维网  




### 0.万维网

万维网在互联网上运行

互联网是传递数据的管道，各种程序都会用，其中传输最多数据的程序是分布在全球数百万个服务器上的万维网

可以用"浏览器"来访问万维网。



**页面**（page）：万维网的基本单位

**超链接**（ Hyperlinks）：点文字或图片可以去到另一个页面。这些超链接形成巨大的互联网络，这就是"万维网"名字的由来。

- Vannevar Bush  描述一个假想的机器 Memex，提出了关联式索引..（associative indexing）。


**超文本**（hypertext）:文字超链接

**统一资源定位器** (Uniform Resource Locator,URL) :网页的唯一网址

**超文本传输协议**(HyperText Transfer Protocol,HTTP ):HTTP的第一个标准，HTTP 0.9，创建于1991年，只有一个"GET" 指令。我们想要的是"courses"页面,向服务器发送指令:"GET /courses"，该指令以"ASCII编码"发送到服务器，服务器会返回该地址对应的网页 ，然后浏览器会渲染到屏幕上。

**状态码**（status code）：在之后的版本，HTTP添加了状态码，状态码放在请求前面，代表所访问网页的状态。举例，状态码 200 代表 "网页找到了,给你"，状态码400~499代表客户端出错，比如网页不存在，就是可怕的404错误。

**超文本标记语言**（HyperText Markup Language，HTML）

“超文本"的存储和发送都是以普通文本形式，纯文本无法表明什么是链接，什么不是链接。所以有必要开发一种标记方法，因此开发了 超文本标记语言（HTML)。

网页：HTML5，层叠样式表 (Cascading Style Sheets，CSS)，JavaScript



### 1.万维网发展史

网页浏览器可以和网页服务器沟通，浏览器不仅获取网页和媒体，获取后还负责显示。


第一个浏览器和服务器，是 Tim Berners-Lee 花了 2 个月在 CERN （"欧洲核子研究所"）写的。为了做出来，他同时建立了几个最基本的网络标准，URL, HTML 和 HTTP。不过公平点说，他研究超文本系统已经有十几年了。和同事在 CERN 内部使用一阵子后，在 1991 年发布了出去，万维网就此诞生。



万维网有开放标准，大家都可以开发新服务器和新浏览器。因此"伊利诺伊大学香槟分校"的一个小组，在 1993 年做了 Mosaic 浏览器
——第一个可以**在文字旁边显示图片**的浏览器（之前浏览器要单开一个新窗口显示图片），还引进了书签等新功能，界面友好（had a friendly GUI interface），使它很受欢迎



随着万维网日益繁荣，人们越来越需要搜索。起初人们会维护一个目录，链接到其他网站，其中最有名的叫"**Jerry和David的万维网指南**"

，1994年改名为Yahoo。




随着网络越来越大，人工编辑的目录变得不便利所以开发了搜索引擎。长的最像现代搜索引擎的最早搜素引擎，叫**JumpStation**

它有 3 个部分：

**爬虫**：一个跟着链接到处跑的软件，每当看到新链接，就加进自己的列表里

不断扩张的**索引**：记录访问过的网页上，出现过哪些词
**查询索引的搜索算法**：举个例子，如果我在 JumpStation 输入"猫"，每个有"猫"这个词的网页都会出现

早期搜索引擎的排名方式取决于 **搜索词在页面上的出现次数**。



搜索引擎 **Google** 改进了排序方法，**按照链接指向的多少来排序**



### 2.网络中立性（Net Neutrality）

平等地对待每个数据包，速度和优先级应该是一样的。

节流(Throttled) 意思是故意给更少带宽和更低优先级

支持网络中立性：没有中立性后，服务商可以推出提速的"高级套餐"，给剥削性商业模式埋下种子。另外，Netflix和Google这样的大公司可以花钱买特权而小公司，比如刚成立的创业公司 会处于劣势，阻止了创新。

反对网络中立性：市场竞争会阻碍不良行为，如果供应商把客户喜欢的网站降速 ， 客户会离开供应商



## 第 31 集：计算机安全  



### 1. 保密性, 完整性, 可用性 

计算机为了安全，要实现三性

保密性（Secrecy）：只有有权限的人，才能读取计算机系统和数据。黑客泄露别人的信用卡信息，就是攻击保密性。

完整性（Integrity）：只有有权限的人，才能使用和修改系统和数据。黑客知道你的邮箱密码，假冒你发邮件，就是攻击"完整性"。

可用性（Availability）：有权限的人，可以随时访问计算机系统和数据。**拒绝服务攻击**(Denial of Service Attacks，DDOS) 就是黑客发大量的假请求到服务器，让网站很慢或者挂掉，这就是攻击"可用性"。



### 2.威胁模型 Threat Model 

为了实现这三个目标，安全专家会从抽象层面想象"敌人"可能是谁，这叫"威胁模型分析"。

模型会对攻击者有个大致描述：能力如何，目标可能是什么，可能用什么手段。攻击手段又叫"攻击矢量"（attack vector）。

"威胁模型分析"让你能为特定情境做准备，不被可能的攻击手段数量所淹没。



很多安全问题可以总结成两个：你是谁？你能访问什么？

权限应该给合适的人，拒绝错误的人



### 3.身份验证 (Authentication) 的三种方式：

What you know, 你知道什么 ex、用户名和密码   增加密码复杂度

破： "暴力攻击"，试遍一切可能。

防：如果你错误尝试3次，有些系统会阻止你继续尝试，或让你等一会儿。

破：黑客可以控制数以万计的计算机，形成一个僵尸网络用这么多计算机同时尝试密码 

What you have, 你有什么      ex.手机确认

What you are, 你是什么         ex. 生物识别验证，比如指纹识别器和虹膜扫描仪



对于重要账户，安全专家建议用两种或两种以上的认证方式，这叫"双因素"或"多因素"认证（two-factor or multi-factor authentication.）



###  4.访问控制 Access Control

系统知道你是谁后，需要了解你的权限，这可以通过"权限"或"访问控制列表"（Permissions or Access Control Lists,ACL）来实现，其中描述了用户对每个文件，文件夹和程序的访问权限。"读"权限允许用户查看文件内容，"写"权限允许用户修改内容，"执行"权限允许用户运行文件，比如程序。

假设我们有不同的权限级别。用户不能"读上", 不能读等级更高的信息。用户不能"写下"，这样确保了高权限文件的内容不会被泄露到低权限文件里。这个**"不能向上读，不能向下写**"（"no read up, no write down"）的方法 叫 **Bell-LaPadula 模型**。



### 5.安全内核  "security kernel"

安全内核，又称**"可信计算基础**"（"trusted computing base"），一组尽可能少的操作系统软件，安全性都是接近可验证的


构建安全内核的挑战在于 决定内核应该有什么，代码越少越好！



### 6.独立安全检查和质量验证 Independent Verification and Validation.

正式验证代码的安全性 是一个活跃的研究领域。我们现在最好的手段，叫"独立安全检查和质量验证"

让一群安全行业内的软件开发者来审计代码，因为写原始代码的人通常很难找到错误。



### 7.隔离 Isolation, 沙盒 Sandbox

优秀的开发人员，应该计划当程序被攻破后，如何限制损害，控制损害的最大程度，并且不让它危害到计算机上其他东西，这叫"隔离"。要实现隔离，我们可以"沙盒"程序，方法是给每个程序独有的内存块，其他程序不能动。一台计算机可以运行多个虚拟机，如果一个程序出错，最糟糕的情况是它自己崩溃，或者搞坏它处于的虚拟机。计算机上其他虚拟机是隔离的，不受影响。


## 第 32 集：黑客与攻击  

### 0.黑客 -hackers

黑客凭技术知识 闯入计算机系统。


"白帽子"（White Hats）：寻找并修复软件漏洞 ，让系统更安全，他们经常被公司和政府雇来做安全评估

"黑帽子"（ Black Hats）：窃取，利用和销售计算机漏洞和数据


黑客的动机有很多种，有些是好玩和好奇，而网络罪犯一般是为了钱，还有的叫"黑客行动主义者"（通过黑客手段影响社会或达到政治目的）

### 1.社会工程学 -Social Engineering

黑客入侵最常见的方式不是通过技术，而是欺骗别人，这叫"社会工程学"，欺骗别人让人泄密信息或让人安装易于攻击的系统。

### 2.钓鱼 -Phishing

最常见的攻击是网络钓鱼。


银行发邮件叫你点邮件里的链接，登陆账号，然后你会进入一个像官网的网站，但实际上是个假网站，当你输入用户名和密码时，信息会发给黑客，然后黑客就可以假扮你登陆网站。

### 3.假托 -Pretexting

攻击者给某个公司打电话，假装是IT部门的人，攻击者的第一通电话一般会叫人转接，这样另一个人接的时候，电话看起来像内部的，然后让别人把电脑配置得容易入侵，或让他们泄露机密信息，比如密码或网络配置。

### 4.木马 -Trojan Horses

邮件里带"木马"也是常见手段。木马会伪装成无害的东西，比如照片或发票，但实际上是恶意软件。

恶意软件有很多种，有的会偷数据，比如银行凭证，有的会加密文件，交赎金才解密，也就是"勒索软件"。

### 5.NAND镜像 -NAND Mirroring

来避免输错密码后等待

如果能物理接触到电脑，可以往内存上接几根线复制整个内存。复制之后，暴力尝试密码，直到设备让你等待，这时只要把复制的内容覆盖掉内存本质上重置了内存，就不用等待，可以继续尝试密码了。

### 6.漏洞利用- Exploit

远程攻击一般需要攻击者利用系统漏洞来获得某些能力或访问权限，这叫**"漏洞利用"**(Exploit)



一种常见的漏洞利用叫**"缓冲区溢出"**（buffer overflow）。"缓冲区"是一种概称，指预留的一块内存空间。

缓冲区溢出会覆盖掉相邻的数据，有时只会让程序或系统崩溃，因为重要值被垃圾数据覆盖了。但攻击者可以更巧妙地利用这个漏洞(bug)，注入有意义的新值到程序的内存中，比如把"is_admin"的值改成true，有了任意修改内存的能力，黑客可以绕过"登录"之类的东西，甚至使用那个程序劫持整个系统。

防止缓冲区溢出的手段：

 1.**"边界检查"**（bounds checking）：复制之前先检查长度，许多现代编程语言自带了边界检查

2.程序也会**随机存放变量在内存中的位置**，比如我们之前假设的"is_admin"，这样黑客就不知道应该覆盖内存的哪里，导致更容易让程序崩溃，而不是获得访问权限

3.程序也可以在缓冲区后，留一些不用的空间，然后跟踪里面的值，看是否发生变化。如果发生了变化，说明有攻击者在乱来。这些不用的内存空间叫"金丝雀"。

### 7. 代码注入 Code Injection

最常用于攻击用数据库的网站，几乎所有大网站都用数据库
**"结构化查询语言"**（Structured Query Language，SQL）是一种流行的数据库API




当试用户试图"登录"，值会发到服务器，服务器会运行代码，检查用户名是否存在，如果存在，看密码是否匹配。


为了做检查，服务器会执行一段叫 "SQL查询" （ SQL query）的代码


首先，语句要指定从数据库里查什么数据

在这个例子中，我们想查的是密码 (password) (SELECT password)
还要指定从哪张表查数据(FROM users)，我们假设所有用户数据都存在 "users" 表里
最后，服务器不想每次取出一个巨大的包含所有用户的密码列表，
所以用 username = '用户名'，代表只要这个用户，用户输的值会复制到"SQL查询"

所以实际发到 SQL 数据库的命令，是这样的 ：SELECT password FROM users Where username='philbin'



**SQL命令以分号结尾**

把"SQL命令"输入到用户名里登录，比如：'philbin';DROP TABLE users;

命令如下：SELECT password FROM users Where username='philbin';DROP TABLE users;



第一条被执行的命令是：

如果有个用户叫"whateer"，数据库将返回密码，因为我们不知道密码，所以会出错，服务器会拒绝我们

如果没有一个用户叫"whatever"，数据库会返回空密码或直接错误，服务器也会拒绝我们

下一个SQL命令："drop table users" 就是我们注入的命令，这条命令的意思是 ，删掉 users 这张表。我们甚至不需要侵入系统，没有猜到正确的用户名和密码，也能把代码注入到程序中，造成混乱。



很多用户名和密码表单，不让你输入特殊字符，比如分号或者括号，作为第一道防御


好的服务器也会清理输入，比如修改或删除特殊字符，然后才放到数据库查询语句里

### 8.零日漏洞 Zero Day Vulnerability

当软件制造者不知道软件有新漏洞被发现了，这个漏洞被称为“零日漏洞”

保持系统更新非常重要，很多更新都是安全性补丁

### 9.计算机蠕虫 Worms和僵尸网络 Botnet

如果有足够多的电脑有漏洞，让恶意程序可以在电脑间互相传播，这种恶意程序叫做蠕虫。

如果黑客拿下大量电脑，这些电脑可以组成"僵尸网络"（botnet），可以用于很多目的，比如发大量垃圾邮件，用别人电脑的计算能力和电费挖 Bitcoin，或发起"拒绝服务攻击"（Distributed Denial of Service，DDoS）攻击服务器。DDoS 就是僵尸网络里的所有电脑发一大堆垃圾信息，堵塞服务器，要么迫使别人交钱消灾，或纯粹为了作恶。




## 第 33 集：加密  


### 1、多层防御  Defence in depth 

世上不存在100%安全的系统，所以系统架构师会部署"多层防御"，用多层不同的安全机制来阻碍攻击者

### 2、 密码学（Cryptography）

  加密算法(Cipher) 

把明文转成密文叫"加密"(encryption)，把密文恢复回明文叫"解密"(decryption)



### 3、**替换加密** （Substitution cipher）

**凯撒加密** （Caesar cipher）：把字母向前移动三个位置，比如D变成A。

**替换加密** （Substitution cipher）：凯撒密码是其中一种。算法把每个字母替换成其他字母。但有个巨大的缺点是，字母的出现频率是一样的，熟练的密码破译师可以从统计数据中发现规律，进而破译密码。



**德国 Enigma 加密机**  一种进阶的替换加密，每一次的映射都不同。

![e33-Enigma](E:\自我提升\计算机科学速成课\image\e33-Enigma.jpg)

电路是双向的，加密和解密的步骤是一样的，所以发送机和接收机的初始配置相同。

缺点：字母加密后一定会变成另一个字母



### 4、**移位加密**（ Permutation cipher）

**"列移位加密"**（columnar transposition cipher）：我们按某一顺序明文填入网格，为了加密信息，我们换个顺序来读

### 5、"数据加密标准" - Data Encryption Standard (DES)

早期加密算法中，应用最广泛的是 IBM 和 NSA 于1977年开发的"数据加密标准"。


DES最初用的是56 bit长度的二进制密钥，意味着有2的56次方，或大约72千万亿个不同密钥。在1977年时，也许 NSA 有这能力，但没有其他人有足够计算能力 来暴力破解所有可能密钥。但到1999年，一台25万美元的计算机能在两天内 \N 把 DES 的所有可能密钥都试一遍，让 DES 算法不再安全

### 6、"高级加密标准" - Advanced Encryption Standard (AES)

2001 年出了：高级加密标准（AES）。AES 用更长的密钥 - 128位/192位/256位 - 让暴力破解更加困难


AES将数据切成一块一块，每块16个字节，\N 然后用密钥进行一系列替换加密和移位加密，再加上一些其他操作，进一步加密信息，每一块数据，会重复这个过程10次或以上。

AES 在性能和安全性间取得平衡。如今AES被广泛使用，比如iPhone上加密文件，用 WPA2 协议在 WiFi 中访问 HTTPS 网站



### 7、密钥交换 - Key exchange

**以上所有加密技术依赖于发送者和接收者都知道密钥。发件人用密钥加密，收件人用相同的密钥解密。**如今，我们需要某种方法 在公开的互联网上传递密钥给对方。密钥交换是一种不发送密钥，但依然让两台计算机在密钥上达成共识的算法，我们可以用"单向函数"来做。

**单向函数**（one-way functions）是一种数学操作，很容易算出结果，但想从结果逆向推算出输入非常困难。

实例：**迪菲-赫尔曼密钥交换** - Diffie-Hellman Key Exchange

在 Diffie-Hellman 中，单向函数是模幂运算

横幂运算：把两个数做幂计算，然后除以第三个数字，最后拿到我们想要的余数。

比如：3的某次方 模31，余数是7,你要试很多次，才能知道次方是多少.如果把数字变长一些，想找到秘密指数是多少，几乎是不可能的。



用模幂运算 算出双方共享的密钥

![e33-Diffie-Hellman Key Exchange](E:\自我提升\计算机科学速成课\image\e33-Diffie-Hellman Key Exchange.jpg)首先，我们有公开的值 - 基数和模数


A选秘密指数：X，把 B^X mod M 的结果发给B

B选秘密指数：X，把 B^X mod M 的结果发给A


为了算出 双方共用的密钥，A把B发过来的指数乘上自己的秘密指数，数学上相等于  B的XY次方 模M


John也一样做，拿我给他的数 进行模幂运算，最终得到一样的数

双方有一样的密钥，即使我们从来没给对方发过各自的秘密指数

我们可以用这个大数字当密钥，用 AES 之类的加密技术来加密通信



"Diffie-Hellman 密钥交换"是建立共享密钥的一种方法。


双方用一样的密钥加密和解密消息，这叫**"对称加密"**（symmetric keys），凯撒加密，英格玛，AES 都是"对称加密"

### 8. 非对称加密 - Asymmetric encryption

有两个不同的密钥，一个是公开的，另一个是私有的。人们用公钥加密信息，只有有私钥的人能解密，或者反过来，这叫非对称解密。

这种做法用于签名，服务器可以用私钥加密，任何人都可以用服务器的公钥解密。这能证明数据来自正确的服务器或个人，而不是某个假冒者。

目前最流行的"非对称加密"技术是 RSA，名字来自发明者： Rivest, Shamir, Adleman.



## 第 34 集：机器学习与人工智能  
机器学习的本质：机器学习算法让计算机可以从数据中学习，然后自行做出预测和决定

机器学习是为了实现人工智能这个更宏大目标的技术之一



**分类**  Classification

**分类器** Classifier：做分类的算法

**特征** Feature :虽然我们可以用 照片和声音 来训练算法,很多算法会减少复杂性,把数据简化成 "特征"。"特征"是用来帮助"分类"的值。

**标记数据** Labeled data : 特征值+种类

**决策边界**  Decision boundaries  : 最佳区分的条件。机器学习算法的目的是最大化正确分类 + 最小化错误分类

**混淆矩阵**  Confusion matrix  ：记录正确数和错误数的表 

**未标签数据**   Unlabeled data ：未分类的物体，我们根据它的特征, 并绘制到决策空间上

**决策树** Decision tree  ：生成决策树的机器学习算法需要选择用什么特征来分类，每个特征用什么

**森林** Forests ：一些算法甚至用多个"决策树"来预测

**支持向量机** Support Vector Machines ：本质上是用任意线段来切分决策空间，不一定是直线，可以是多项式或其他数学函数。机器学习算法负责找出最好的线，最准的决策边界

"决策树"和"支持向量机"这样的技术 发源自统计学（用数据做决定）。



**人工神经网络** Artificial Neural Network ：

不用统计学的方法。算法灵感来自大脑里的神经元。人造神经元可以接收多个输入，然后整合并发出一个信号，它不用电信号或化学信号，而是吃数字进去，吐数字出来，一层层神经元形成神经元网络。

输入层-隐藏层（不是只能有一层，可以有很多层）-输出层

模拟人类学习的过程，将数据进行加权求和以及修正（加减一个固定的值）等一系列处理。做神经网络时，这些偏差和权重，一开始会设置成随机值，然后算法会调整这些值 来训练神经网络，使用"标记数据"来训练和测试，逐渐提高准确性。

神经元有激活函数（activation function），它也叫传递函数（transfer function），会应用于输出，对结果执行最后一次数学修改。

加权，求和，偏置，激活函数会应用于一层里的每个神经元，并向前传播，一次一层。



训练更复杂的网络需要更多的计算量和数据，尽管神经网络50多年前就发明了，深层神经网络直到最近由于强大的处理器和超快的GPU人的出现才成为可能。



**"弱AI"**（ Weak AI ）/"窄AI"（ Narrow AI）：只能做特定任务

 **强AI** （Strong AI）：通用的，和人一样智能的AI叫做强AI，目前没有人能做到。



**强化学习** Reinforcement Learning：学习什么管用，什么不管用，自己发现成功的策略，这叫强化学习。


## 第 35 集：计算机视觉  
"计算机视觉"（computer vision）的目标是让计算机理解图像和视频

### 1、颜色跟踪算法

颜色跟踪算法是一个个像素搜索，因为颜色是在一个像素里。



跟踪一个颜色物体，比如一个粉色的球：首先，我们记下球的颜色，保存最中心像素的 RGB 值


然后给程序喂入图像，让它找最接近这个颜色的像素


算法可以从左上角开始，逐个检查像素，计算和目标颜色的差异

检查了每个像素后，最贴近的像素，很可能就是球
不只是这张图片，我们可以在视频的每一帧图片跑这个算法，跟踪球的位置


干扰因素：光线，阴影和其它影响，晚上效果会比较差。而且，如果球衣的颜色和球一样，算法就完全晕了


除非环境可以严格控制，很少用这类颜色跟踪算法





### 2、核/过滤器 （kernel or filter）

颜色跟踪算法不适合占多个像素的特征，比如多个像素组成的物体的边缘。为了识别这些特征，算法要一块块像素来处理，每一块都叫"块"（ patch）

**核/过滤器** ：用来检测不同块特征的数学符号，里面的数字用来做像素乘法，总和 存到中心像素里。用于找出图像的特定特征。突出不同的特征，要用不同的"核"。核能做很多种图像转换。



### 3、**"卷积"**（ convolution）

把所有像素转成了灰度值（灰度图中），把"核"的中心，对准感兴趣的像素，这就相当于指定了每个像素要乘的值，然后把所有数字加起来，最后结果成为新像素值，放入中心像素。把 核 应用于像素块，这种操作叫**"卷积"**（ convolution）。



### 4、 检测垂直边缘的算法

某像素是垂直边缘的可能性，取决于左右两边像素的颜色差异程度。左右像素的区别越大，这个像素越可能是边缘。

![e35-kernel or filter](E:\自我提升\计算机科学速成课\image\e35-kernel or filter.jpg)

如果把"核"用于照片中每个像素（对所有像素卷积），结果如下：垂直边缘的像素值很高，水平边缘（比如背景里的平台）几乎看不见。

![e35-vertical edges convulution](E:\自我提升\计算机科学速成课\image\e35-vertical edges convulution.jpg)



### 5、典型的核

**Prewitt 算子** （Prewitt Operators）：水平和垂直边缘增强的核

![e35-Prewitt operators](E:\自我提升\计算机科学速成课\image\e35-Prewitt operators.png)



![e35-blur](E:\自我提升\计算机科学速成课\image\e35-blur.jpg)

![e35-sharpen](E:\自我提升\计算机科学速成课\image\e35-sharpen.jpg)



### 6、**维奥拉·琼斯 人脸检测** Viola-Jones Face Detection

"核"也可以像饼干模具一样，匹配特定形状。

鼻梁往往比鼻子两侧更亮，所以线段敏感的"核"对这里的值更高。眼睛是一个黑色圆圈被外层更亮的一层像素包着，是包了一圈对比色的区域。有其它"核"对这种模式敏感，当计算机扫描图像时，最常见的是用一个窗口来扫，可以找出人脸的特征组合，虽然每个"核"单独找出脸的能力很弱 ，但组合在一起会相当准确。不是脸但又有一堆脸的特征在正确的位置，这种情况不太可能，这是一个早期很有影响力的算法**维奥拉·琼斯 人脸检测**的基础。

### 7、卷积神经网络 Convolutional Neural Networks

"卷积神经网络"用一堆神经元处理图像数据，每层都会输出一个新图像，本质上是被不同的"核"处理了，输出会被后面一层神经元处理，卷积卷积再卷积。

第一层可能会发现"边缘"这样的特征

下一层可以在这些基础上识别，比如由"边缘"组成的角落
然后下一层可以在"角落"上继续卷积，下一些可能有识别简单物体的神经元，比如嘴和眉毛


然后不断重复，逐渐增加复杂度，直到某一层把所有特征放到一起：眼睛，耳朵，嘴巴，鼻子，然后说："啊哈，这是脸！"

![e35-Convolutional Neural Networks](E:\自我提升\计算机科学速成课\image\e35-Convolutional Neural Networks.jpg)



"维奥拉·琼斯"和"卷积神经网络"不只是认人脸，还可以识别手写文字， CT 扫描中发现肿瘤，监测马路是否拥堵



### 8、面部标记点（Facial landmarks）

识别出脸之后，可以用更专用的计算机视觉算法来定位面部标志。

**"情感识别算法"（**emotion recognition algorithm）：有了鼻尖标志点，通过计算点之间的距离可以判断眼睛有没有张开，也可以跟踪眉毛的位置，眉毛相对眼睛的位置可以代表惊喜或喜悦，根据嘴巴的标志点，检测出微笑也很简单。这些信息可以用来识别情绪，然后电脑做出合适的行为。

**生物识别**（biometric data）：面部标记点 也可以捕捉脸的形状，比如两只眼睛之间的距离，以及前额有多高，做生物识别。

**理解用户的身体语言**：跟踪手臂和全身的标记点，让计算机理解用户的身体语言，比如用户给联网微波炉的手势。智能电视和智能辅导系统 会根据用户的手势和表情来回应。

## 第 36 集：自然语言处理  

### 0、概念梳理

**计算机语言**：机器语言和更高层次的编程语言等，词汇量一般很少，而且非常结构化，代码只能在拼写和语法完全正确时，编译和运行

**"自然语言"**（natural languages）：人类语言。自然语言有大量词汇，有些词有多种含义，不同口音，以及各种有趣的文字游戏，人们在写作和说话时也会犯错（连读、发错音、遗漏关键细节导致意思模糊两可）
**"自然语言处理"**（Natural Language Processing，NLP）：结合了计算机科学和语言学的 一个跨学科领域，目的是让计算机拥有语音对话的能力。



### 1、语言理解

**词性**  （ Parts of speech  ）：名词，代词，冠词，动词，形容词，副词，介词，连词和感叹词。把句子切成一块块，方便处理。

**短语结构规则** （ Phrase structure rules  ）：代表语法规则。

I should also note that phrase structure rules, and similar methods that codify language can be used by computers to generate natural language text. This works particularly well when data is stored in a web of semantic information,where entities are linked to one another in meaningful relationships,providing all the ingredients you need to craft informational sentences.

Google's version of this is called Knowledge Graph. At the end of 2016,it contained roughly seventy billion facts about, and relationships between, different entities.
**These two processes, parsing and generating text, are fundamental components of natural language chatbot**s——computer programs that chat with you.

**分析树**  （Parse tree  ）：它给每个单词标了可能是什么词性，也标明了句子的结构。数据块更小 更容易处理。每次语音搜索，都有这样的流程。

通过**词性 Parts of speech**和**短语结构规则 Phrase structure rules**构建**分析树 Parse tree，**并结合**语言模型 Language Model**来实现**语言的理解**。

### 2、**语音识别 Speech recognition**

1980,1990年代 计算机性能的大幅提升，实时语音识别变得可行，同时也出现了处理自然语言的新算法，不再是手工定规则，而是用机器学习，从语言数据库中学习，如今准确度最高的语音识别系统 用深度神经网络。



原理：用麦克风记录声波随时间变化的振幅，在利用**快速傅立叶变换** （Fast Fourier Transform）把波形图转换成横坐标是时间、纵坐标是不同频率的振幅的谱图（spectrogram），颜色越亮，频率的声音越大 。所有元音的谱图都有很大不同，这让计算机可以识别元音，然后识别出整个单词。

立体声系统的 EQ 可视化器（stereo system's EQ visualizer）就是谱图。



**"音素"**（phonemes）：构成单词的声音片段

when I say: "she.. was.. happy"，We can see our "eee" sound here, and "aaa" sound here.We can also see a bunch of other distinctive sounds,like the "shh" sound in "she",the "wah" and "sss" in "was", and so on.

![e35-Speech recognition](E:\自我提升\计算机科学速成课\image\e35-Speech recognition.jpg)语音识别软件 知道这些音素。英语有大概44种音素。

语音识别本质上变成了音素识别，还要把不同的词分开，弄清句子的开始和结束点，最后把语音转成文字。

因为口音和发音错误等原因，人们说单词的方式略有不同。所以结合**语言模型**（language model）后，语音转文字的准确度会大大提高。语言模型里面有单词顺序的统计信息。比如："她"后面很可能跟一个形容词，后面很少是名词。如果不确定是 happy 还是 harpy，会选 happy，因为语言模型认为可能性更高。



###  3、语音合成 Speech Synthesis

核语音识别反过来，把一段文字，分解成多个声音，然后播放这些声音。

早期语音合成技术，可以清楚听到音素是拼在一起的。

到了1980年代，技术改进了很多，但音素混合依然不够好，产生明显的机器人声。

如今，电脑合成的声音，比如 Siri, Cortana, Alexa好了很多，虽然还不够像人，但非常非常接近了。




## 第 37 集：机器人  




bot：虚拟机器人程序

agent：代理、智能体



### 1、数控机器

第一台计算机控制的机器出现在1940年代晚期。

这些计算机数控( Computer Numerical Control)的机器，简称 CNC 机器。可以执行一连串 程序指定的操作。

精细的控制 让我们能生产之前很难做的物品，比如从一整块铝 加工出复杂的螺旋桨。CNC 机器大大推进了制造业，不仅提高了制造能力和精确度 还降低了生产成本

### 2、可编程工业机器人

1960年 Unimate，第一个商业贩卖的 可编程工业机器人


第一个商业贩卖的 可编程工业机器人叫 Unimate，于1960年卖给通用汽车公司

它可以把压铸机做出来的热金属成品提起来，然后堆起来

机器人行业由此开始


很快，机器人开始堆叠货盘，焊接，给汽车喷漆等等

对于简单运动 - 比如机器爪子 在轨道上来回移动，可以指示它移动到特定位置。它会一直朝那个方向移动，直到到达 ，然后停下来

这种行为 可以用**简单控制回路**（simple control loop）做：

### 3.机器人控制的回路

 **负反馈回路** （negative feedback loop）：判断机器人的位置，如果没到目的位置，那么继续前进，再次判断位置，直至到达目的位置停下。因为我们在不断缩小 当前位置和目标位置的距离，这个控制回路 更准确的叫"负反馈回路"。

**比例-积分-导数控制器** （**PID 控制器**，Proportional–Integral–Derivative controller ）：

 控制三个值：

比例值——实际值（可能有一定滞后，或者是实时的。）和理想值差多少。"实际值"和"理想值"的差距越大，就越用力，换句话说，它是"比例控制"的

积分值——一段时间误差的总和，如果这个值很大，说明比例控制不够，要继续用力前进

导数值（微分值）——期望值和实际值之间的变化率，用来避免未来的错误，这也叫预期控制（anticipatory control），来控制进程。

比如前进的太快，要稍微放松一点，避免冲过头。


这三个值有不同权重，共同控制系统


PID 控制器到处都是，比如汽车里的巡航控制，无人机调整螺旋桨速度保持水平。更高级的机器人一般需要多个控制回路同时运行来保持机器人平衡，调整肢体位置，等等



### 4. 机器人三定律 Three Laws of Robotics

- **第零法则**

> 机器人不得伤害整体人类，或坐视整体人类受到伤害；

- **第一法则**

> 除非违背第零法则，否则机器人不得伤害人类，或坐视人类受到伤害；

- **第二法则**

> 机器人必须服从人类命令，除非命令与第零或第一法则发生冲突；

- **第三法则**

> 在不违背第零、第一或第二法则之下，机器人可以保护自己。




## 第 38 集：计算机心理学  



### 0、计算机中用到的心理学原理

为了做出更好的计算机，我们需要了解人类心理学。

社会心理学 认知心理学 行为心理学 感知信息学



### 1、**易用度**（usability）

人造物体，比如软件，达到目的的效率有多高

### 2、视觉（颜色）

人类擅长给颜色强度排序，所以颜色强度很适合现实连续值；

而人类不擅长给颜色排序，所以如果数据没有顺序，用不同颜色就很合适，如分类数据。

### 3、认知系统（分块记忆）

信息分块会更好记。分块是指把信息分成更小，更有意义的块。

从计算机的角度来看，分块更费时费空间，效率更低，但这对人类更有效率，碰到这种抉择时，我们总是以人类优先。

如电话号码分块（317-555-3897 比 3175553897 好记  ），界面设计分块（下拉菜单 、带按钮的菜单栏）。

### 4、直观功能（affordances）

直观功能为如何操作物体提供线索，如平板用于推，旋钮用来转，插槽用来插东西。直观功能做得好，用户只需要看一眼就知道怎么搞，而不需要其他东西来说明。

直观功能"广泛用于图形界面，这是图形界面比命令行更容易用的原因之一。



和直观功能相关的一个心理学概念是**认出和回想**，这就是选择题比填空题简单的原因。

一般来说，用感觉触发记忆会容易得多，比如文字、图片和声音，所以我们用图标表示功能，如垃圾桶表示回收站。

但是，让所有菜单选项好找好记，有时候意味着用的时候会慢一些。这与另一个心理学概念冲突："专业知识”（expertise），当你用界面熟悉之后，速度会更快一些，建立如何高效完成事情的"心理模型"。所以 好的界面应该提供多种方法来实现目标，一个好例子是复制粘贴，可以在"编辑"的下拉菜单中找到，也可以用快捷键，两者都不耽误。

### 6、情感反馈

我们也希望电脑能有一点情商，能根据用户的状态做出合适的反应，让使用电脑更加愉快。

因为情绪会影响日常活动，比如学习，沟通和决策。情感系统会用传感器，录声音，录像（你的脸）以及生物指标，比如出汗和心率，得到的数据和计算模型结合使用，模型会估算用户的情绪，给最好的回应用户。



### 7、"以计算机为媒介沟通"（computer-mediated communication，"CMC"）


包括同步通信（ synchronous communication ） - 所有参与者同时在线进行视频通话以及异步通信（asynchronous communication） - 比如推特，邮件，短信，人们可以随时随地回复信息


研究人员还研究用户怎么用表情包，怎么轮换发言，以及用不同沟通渠道时，用词有什么区别。


一个有趣的发现是，比起面对面沟通，人们更愿意在网上透露自己的信息。


心理学研究也表明，如果想说服，讲课，或引起注意 ，眼神注视非常重要。在谈话时看着别人叫 相互凝视（mutal gaze），这被证明可以促进参与感 帮助实现谈话目标

在录像讲座中，老师很少直视相机 ，一般是看在场学生。这会让在线看视频的人  没什么参与感。为此，研究人员发展了计算机视觉、开发了图形软件 ，来纠正头部和眼睛，看视频的人会觉得对方在直视他们。这叫**"增强凝视"**（augmented gaze）。类似技术也用于视频会议。

### 8、拟人化

人也喜欢像人的机器人。

人机交互（Human-Robot Interaction – or HRI），是一个研究人类和计算机交互的领域。

恐怖谷（uncanny valley）：

![e38-uncanny valley](E:\自我提升\计算机科学速成课\image\e38-uncanny valley.jpg)


## 第 39 集：教育科技  
### 0.加强学习效率

 通过调速，暂停等技巧，做视频中提供的练习

这些主动学习的技巧已被证明 ，可以把学习效率提升10倍或以上

### 1.大型开放式在线课程 - Massive Open Online Courses (MOOC)

好的大学没有围墙



### 2.智能辅导系统 - Intelligent Tutoring Systems

些算法提供个性化学习体验，为了个性化推荐，软件需要了解用户知道什么，不知道什么，在正确的时间提供正确的资料，让用户练习没理解的难的部分，而不是给出用户已经学会的内容。这种系统一般用 AI 实现，泛称叫法是"智能辅导系统"。



**"判断规则"** （Production rule）可以用来代表学生的常犯错误，这些"判断规则"叫**"错误规则"**（"buggy rules"）。

学生做完一个步骤后可能触发多个"判断规则"，所以"判断规则"会和算法结合使用，判断学生写错的可能原因，让学生得到有用反馈。


"判断规则"+选择算法，组合在一起成为 **"域模型"**（Domain Model），它给知识，解决步骤和一门学科 比如代数，用一种"正式写法"（ formal representation）来表示。域模型可以用来 帮助学习者解决特定问题。但它无法带着学习者以正确顺序搞定整个学科该上的所有课程，因为域模型不记录进度。


因此智能辅导系统 负责创建和维护学生模型，记录学生已经掌握的判断规则，以及还需练习的生疏部分。这正是个性化辅导系统需要的。



**贝叶斯知识追踪** （Bayesian knowledge tracing）：把学生的知识掌握当成隐藏变量，根据学生答题的正确度，更新学生掌握程度的估算值。具体而言，贝叶斯知识追踪有一组方程，会用四个概率（学生已经学会的概率、瞎猜的概率、失误的概率、做题过程中学会的概率），更新学生模型，评估其掌握程度。



### 3.自适应性程序（adaptive sequencing）

"智能辅导系统"通常用 贝叶斯知识追踪，让学生练习技能，直到掌握。为了高效做到这点，软件要选择合适的问题让学生学，这叫自适应式程序，个性化算法的形式之一。

### 4. 教育数据挖掘 Educational Data Mining

常见错误一般哪里难倒学生看学生答题时停顿的时间，观察学生停顿和加速视频的时间段，学生如何在论坛和其他人互动，来评估学生的程度。


## 第 40 集：奇点，天网，计算机的未来  
### 0. 普适计算 Ubiquitous Computing

计算机融入生活的方方面面

让人一刻也不想离开、把计算机整合到所有东西里，用的时候很自然 完全注意不到

### 1.奇点 Singularity

——智能科技的失控性发展

人工智能是否会超越人类智能？

 "智能的准确定义是什么？"

人工智能成长到和人类一样通用，还有很长的路。因为"智能"是难以量化的指标，人们更喜欢用处理能力来区分，但这种衡量智能的方法比较"以计算为中心"。

"技术性失业"

工作的四个维度：体力/思维，重复性/非重复性



### 2.赛博人和数字永生

未来学家 Ray Kurzweil 认为"The Singularity will allow us to transcend limitations of our biological bodies and brains. We will gain power over our fates.... We will be able to live as long as we want. We will fully understand human thinking and will vastly extend and expand its reach."

Transhumanists see this happening in the form of **cyborg**s,where humans and technology merge, enhancing our intellect and physiology.



脑电接口（brain computer interfaces ）


Google Glass 和 微软 Hololens \这样的穿戴式计算机 也在模糊这条界线


"数字永生"（ "Digital Ascension"）

 in the words of Jaron Lanier, "would involve people dying in the flesh and being uploaded into a computer and remaining conscious".

This transition from biological to digital beings might end up being our next evolutionary step...
